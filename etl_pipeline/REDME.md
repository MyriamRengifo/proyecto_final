# üìÇ ETL Pipeline

Esta carpeta contiene los archivos necesarios para el proceso de extracci√≥n, transformaci√≥n y carga (ETL) del proyecto. Incluye notebooks, consultas espec√≠ficas y scripts para integrar las diferentes fuentes de datos.

---

## üìã Contenido de la Carpeta

### 1. **Notebooks**
Los notebooks se encuentran organizados por fuente de datos y prop√≥sito:

- **Google API**:
  - `metadata_sitios.ipynb`: Obtenci√≥n de datos de servicios y  localizaci√≥n mediante las APIs de Google.

- **Overpass API**:
  - `overpass_restaurantes.ipynb`: Extracci√≥n de datos de restaurantes usando Overpass API.
  - `Parques de diversiones Centros comerciales.ipynb`: Extracci√≥n de datos de parques de diversiones y centros comerciales usando Overpass API.
  - `unidad educativa.ipynb`: Extracci√≥n de datos sobre unidades educativas.

- **Yelp Open Dataset**:
  - `ETL_yelp.ipynb`: Transformaci√≥n y limpieza de datos del dataset de Yelp usando Overpass API.

- **Unificaci√≥n de Datos**:
  - `merge_archivos.ipynb`: Unifica los datos de Google, Yelp y Overpass en un √∫nico formato procesado.

---

### 2. **Consultas (`queries`)**
Esta subcarpeta contiene las consultas utilizadas para la extracci√≥n de datos desde Overpass API:

- `overpass_parques_de_diversiones_centrocomerciales_query.overpassql`: Consulta para extraer informaci√≥n de parques y centros comerciales del 2014 al 2024.
- `overpass_unidades_educativas_query.overpassql`: Consulta para extraer datos de unidades educativas del 2014 AL 2024.
- `overpass_restaurants_query.overpassql`: Consulta para extraer datos de restaurantes en 2022 Y 2023.

Las consultas est√°n formateadas para ser utilizadas directamente en Overpass API ,OpenStreetMap,en overpass se nesecita analizar marcas de tiempo (timestamp) en el resultado JSON..

---

## üõ†Ô∏è Notas T√©cnicas

1. **Requisitos**:  
   - Aseg√∫rate de tener configurado un entorno Python con Jupyter Notebook para ejecutar los archivos `.ipynb`.
   - Algunas consultas requieren conexi√≥n a internet para comunicarse con Overpass API o Google API.

2. **Dependencias**:  
   - Los notebooks utilizan bibliotecas como `pandas`, `requests`, y `geopy`. Aseg√∫rate de instalar las dependencias incluidas en `requirements.txt`.

3. **Proceso de ETL**:  
   - Ejecuta los notebooks por orden l√≥gico:  
     1. Obtenci√≥n de datos con **Overpass API**, **Google API** y **Yelp**.  
     2. Procesamiento individual de los datos.  
     3. Unificaci√≥n de los datos con el archivo `merge_archivos.ipynb`.

---
üòä
