{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Descargamos los archivos de la base de datos publica de YELP de su pagina\n",
        "\n",
        "\n",
        "oficial https://www.yelp.com/dataset"
      ],
      "metadata": {
        "id": "F05PJuAmqgD9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4YoKxPUwL9T",
        "outputId": "0bdacf97-36fc-4006-93ac-60b340e5d97c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#librerias\n",
        "import pandas as pd\n",
        "import json\n",
        "from textblob import TextBlob\n",
        "import tarfile\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import random\n",
        "import string\n",
        "import csv"
      ],
      "metadata": {
        "id": "Xczc-VcNxSWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después de descargar el archivo desde la pagina oficial de Yelp  procedemos a descomprimir los archivos que lo conforman"
      ],
      "metadata": {
        "id": "AkRUSxIVqrIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos la ruta del archivo .tgz\n",
        "ruta_tgz = '/content/drive/MyDrive/data/datos en bruto/yelp_dataset.tgz'\n",
        "\n",
        "# Cargamos la ruta de extracción donde se guardara el archivo\n",
        "ruta_extraccion = '/content/sample_data'\n",
        "\n",
        "# Extraemos los archivos que comforman el archivo .tgz\n",
        "try:\n",
        "    with tarfile.open(ruta_tgz, 'r:gz') as archivo_tgz:\n",
        "        archivo_tgz.extractall(path=ruta_extraccion)\n",
        "    resultado = f\"Archivos extraídos exitosamente en: {ruta_extraccion}\"\n",
        "except Exception as e:\n",
        "    resultado = f\"Error al extraer los archivos: {e}\"\n",
        "\n",
        "resultado\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q7Z8ollWxT5P",
        "outputId": "3bae4784-c52e-4301-8743-aa8b9a864731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Archivos extraídos exitosamente en: /content/sample_data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Cambiamos el formato de los archivos YELP de .json a csv"
      ],
      "metadata": {
        "id": "HeAE5vNtvQuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos las rutas de los archivos .json\n",
        "archivos = {\n",
        "    \"business\": \"/content/sample_data/yelp_academic_dataset_business.json\",\n",
        "    \"checkin\": \"/content/sample_data/yelp_academic_dataset_checkin.json\",\n",
        "    \"review\": \"/content/sample_data/yelp_academic_dataset_review.json\",\n",
        "    \"tip\": \"/content/sample_data/yelp_academic_dataset_tip.json\",\n",
        "    \"user\": \"/content/sample_data/yelp_academic_dataset_user.json\"\n",
        "}\n",
        "\n",
        "# Establesemos el tamaño de chunk para procesar los archivos en partes y evitar la saturacion de la memoria\n",
        "chunk_size = 10000\n",
        "\n",
        "# Convertimos cada archivo de .json a .csv usando chunks\n",
        "for nombre, ruta in archivos.items():\n",
        "    try:\n",
        "        # Definimos donde guardaremos el archivo .csv\n",
        "        ruta_salida = f\"/content/sample_data/{nombre}.csv\"\n",
        "\n",
        "        # Usamos chunks para procesar el archivo\n",
        "        with pd.read_json(ruta, lines=True, chunksize=chunk_size) as reader:\n",
        "            for i, chunk in enumerate(reader):\n",
        "                mode = 'w' if i == 0 else 'a'\n",
        "                header = i == 0\n",
        "                chunk.to_csv(ruta_salida, index=False, mode=mode, header=header)\n",
        "\n",
        "        print(f\"Archivo {nombre} convertido y guardado como {ruta_salida}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al convertir {nombre}: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uvBxRmzxaeO",
        "outputId": "ae0c87d5-ec34-45cd-a874-50b7dddbf36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo business convertido y guardado como /content/sample_data/business.csv.\n",
            "Archivo checkin convertido y guardado como /content/sample_data/checkin.csv.\n",
            "Archivo review convertido y guardado como /content/sample_data/review.csv.\n",
            "Archivo tip convertido y guardado como /content/sample_data/tip.csv.\n",
            "Archivo user convertido y guardado como /content/sample_data/user.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al archivo bussines  lo dividimos segun su categoria separando los datos del estado de Florida"
      ],
      "metadata": {
        "id": "BWgJcdsgxeIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos la ruta del archivo business con los datos de Florida\n",
        "ruta_business = \"/content/sample_data/yelp_academic_dataset_business.json\"\n",
        "\n",
        "# Definimos las categorías\n",
        "categorias = {\n",
        "    \"restaurantes\": [\n",
        "        \"restaurant\", \"cafe\", \"espresso bar\", \"dart bar\", \"hookah bar\", \"cafeteria\",\n",
        "        \"cocktail bar\", \"fast food\", \"pizza\", \"grill\", \"barbecue\", \"bistro\", \"brunch\",\n",
        "        \"buffet\", \"bar\"\n",
        "    ],\n",
        "    \"educacion\": [\n",
        "        \"school\", \"college\", \"private educational institution\", \"university\",\n",
        "        \"kindergarten\", \"vocational school\", \"dance school\", \"music school\",\n",
        "        \"education\", \"education center\", \"music conservatory\", \"music store\",\n",
        "        \"music instructor\"\n",
        "    ],\n",
        "    \"supermercados_tiendas_negocios\": [\n",
        "        \"supermarket\", \"grocery store\", \"food store\", \"bakery\", \"candy store\",\n",
        "        \"ice cream shop\", \"convenience store\", \"boutique\", \"furniture store\"\n",
        "    ],\n",
        "    \"entretenimiento\": [\n",
        "        \"cinema\", \"theater\", \"sports complex\", \"aquarium\", \"zoo\", \"museum\",\n",
        "        \"concert\", \"gaming\", \"amusement park\"\n",
        "    ],\n",
        "    \"salud\": [\n",
        "        \"hospital\", \"clinic\", \"dentist\", \"medical center\", \"pharmacy\",\n",
        "        \"treatment center\", \"psychologist\", \"cardiologist\", \"nutritionist\"\n",
        "    ],\n",
        "    \"transporte\": [\n",
        "        \"bus station\", \"train station\", \"airport\", \"taxi\", \"vehicle rental\",\n",
        "        \"transportation service\", \"bicycle shop\", \"car rental\"\n",
        "    ],\n",
        "    \"servicios\": [\n",
        "        \"government office\", \"bank\", \"atm\", \"post office\", \"insurance\",\n",
        "        \"real estate\", \"law firm\", \"courier\", \"cleaning service\"\n",
        "    ],\n",
        "    \"servicios_animales\": [\n",
        "        \"veterinary\", \"pet care\", \"animal hospital\", \"dog park\", \"pet boarding\",\n",
        "        \"dog trainer\", \"animal shelter\"\n",
        "    ],\n",
        "    \"hoteles_y_hospedaje\": [\n",
        "        \"hotel\", \"motel\", \"hostel\", \"bed & breakfast\", \"lodge\", \"resort\",\n",
        "        \"vacation rental\"\n",
        "    ],\n",
        "    \"otros\": []\n",
        "}\n",
        "\n",
        "business_df = pd.read_json(ruta_business, lines=True)\n",
        "\n",
        "# Filtramos solo los negocios que coresponden al estado de Florida\n",
        "florida_business_df = business_df[business_df['state'] == 'FL']\n",
        "\n",
        "# Creamos un directorio de salida para guardar los archivos .csv\n",
        "output_dir = \"/content/categorias_csv/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Clasificamos los negocios de Florida en categorías y guardarlos como .csv\n",
        "for categoria, keywords in categorias.items():\n",
        "    if keywords:\n",
        "        filtered_df = florida_business_df[florida_business_df['categories'].str.contains('|'.join(keywords), case=False, na=False)]\n",
        "    else:\n",
        "        # Filtramos los negocios que no encajan en ninguna categoría\n",
        "        todas_las_categorias = '|'.join(sum(categorias.values(), []))\n",
        "        filtered_df = florida_business_df[~florida_business_df['categories'].str.contains(todas_las_categorias, case=False, na=False)]\n",
        "\n",
        "    # Guardamos los datos filtrados en un archivo .csv\n",
        "    output_path = os.path.join(output_dir, f\"{categoria}.csv\")\n",
        "    filtered_df.to_csv(output_path, index=False)\n",
        "    print(f\"Categoría '{categoria}' guardada en: {output_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3eHMcpTyWZ-",
        "outputId": "b4e5bbb5-94bd-4cdd-813e-a9048a3c89d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categoría 'restaurantes' guardada en: /content/categorias_csv/restaurantes.csv\n",
            "Categoría 'educacion' guardada en: /content/categorias_csv/educacion.csv\n",
            "Categoría 'supermercados_tiendas_negocios' guardada en: /content/categorias_csv/supermercados_tiendas_negocios.csv\n",
            "Categoría 'entretenimiento' guardada en: /content/categorias_csv/entretenimiento.csv\n",
            "Categoría 'salud' guardada en: /content/categorias_csv/salud.csv\n",
            "Categoría 'transporte' guardada en: /content/categorias_csv/transporte.csv\n",
            "Categoría 'servicios' guardada en: /content/categorias_csv/servicios.csv\n",
            "Categoría 'servicios_animales' guardada en: /content/categorias_csv/servicios_animales.csv\n",
            "Categoría 'hoteles_y_hospedaje' guardada en: /content/categorias_csv/hoteles_y_hospedaje.csv\n",
            "Categoría 'otros' guardada en: /content/categorias_csv/otros.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M_YIoGHZ1LYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "•\tRealizamos un merge con los datos de los archivo clasificado por negocio y el archivo checkin basándonos en la columna bussines_id"
      ],
      "metadata": {
        "id": "ovqffZyC1NIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cargamos los directorios donde se encuentran  los achivos\n",
        "input_dir = \"/content/categorias_csv\"\n",
        "checkin_file = \"/content/sample_data/checkin.csv\"\n",
        "output_dir = \"/content/categorias1\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Cargamos el archivo checkin completo\n",
        "print(\"Cargando datos de checkin...\")\n",
        "checkin_df = pd.read_csv(checkin_file)\n",
        "\n",
        "# Procesamos cada archivo de categoría\n",
        "for categoria_file in os.listdir(input_dir):\n",
        "    if categoria_file.endswith(\".csv\"):\n",
        "        try:\n",
        "            categoria_path = os.path.join(input_dir, categoria_file)\n",
        "            print(f\"Procesando categoría: {categoria_file}...\")\n",
        "\n",
        "            categoria_df = pd.read_csv(categoria_path)\n",
        "\n",
        "            # Realizamos el merge con el archivo checkin en business_id\n",
        "            merged_df = pd.merge(categoria_df, checkin_df, on=\"business_id\", how=\"inner\")\n",
        "\n",
        "            # Guardamos el resultado\n",
        "            output_path = os.path.join(output_dir, categoria_file)\n",
        "            merged_df.to_csv(output_path, index=False)\n",
        "            print(f\"Datos combinados guardados en: {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error procesando {categoria_file}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrWIGAN71yRP",
        "outputId": "5bb4f409-284e-40e2-8a6c-53e8a075b05a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando datos de checkin...\n",
            "Procesando categoría: salud.csv...\n",
            "Datos combinados guardados en: /content/categorias1/salud.csv\n",
            "Procesando categoría: otros.csv...\n",
            "Datos combinados guardados en: /content/categorias1/otros.csv\n",
            "Procesando categoría: hoteles_y_hospedaje.csv...\n",
            "Datos combinados guardados en: /content/categorias1/hoteles_y_hospedaje.csv\n",
            "Procesando categoría: restaurantes.csv...\n",
            "Datos combinados guardados en: /content/categorias1/restaurantes.csv\n",
            "Procesando categoría: entretenimiento.csv...\n",
            "Datos combinados guardados en: /content/categorias1/entretenimiento.csv\n",
            "Procesando categoría: supermercados_tiendas_negocios.csv...\n",
            "Datos combinados guardados en: /content/categorias1/supermercados_tiendas_negocios.csv\n",
            "Procesando categoría: servicios_animales.csv...\n",
            "Datos combinados guardados en: /content/categorias1/servicios_animales.csv\n",
            "Procesando categoría: educacion.csv...\n",
            "Datos combinados guardados en: /content/categorias1/educacion.csv\n",
            "Procesando categoría: transporte.csv...\n",
            "Datos combinados guardados en: /content/categorias1/transporte.csv\n",
            "Procesando categoría: servicios.csv...\n",
            "Datos combinados guardados en: /content/categorias1/servicios.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "•\tRealizamos un merge de los archivos del directorio categoría con el archivo review basados en la columna bussines_idy aplicamos un análisis de sentimientos ala columna text"
      ],
      "metadata": {
        "id": "7kV9QFcT2upd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cargamos los directorios de los archivos\n",
        "input_dir = \"/content/categorias1\"\n",
        "review_file = \"/content/sample_data/review.csv\"\n",
        "output_dir = \"/content/categorias2\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Función para mediante analisis de sentimientos calificar la satisfaccion del cliente\n",
        "def clasificar_sentimiento(texto):\n",
        "    polaridad = TextBlob(texto).sentiment.polarity\n",
        "    if polaridad > 0:\n",
        "        return 'positivo'\n",
        "    elif polaridad < 0:\n",
        "        return 'negativo'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "# Procesamos cada archivo de categoría\n",
        "for categoria_file in os.listdir(input_dir):\n",
        "    try:\n",
        "        categoria_path = os.path.join(input_dir, categoria_file)\n",
        "        print(f\"Procesando categoría: {categoria_file}...\")\n",
        "\n",
        "        # Cargamos los datos por categoría\n",
        "        categoria_df = pd.read_csv(categoria_path)\n",
        "\n",
        "        # Leemos el archivo de reviews en chunks para evitar la saturar de la  memoria\n",
        "        chunk_size = 100000\n",
        "        processed_chunks = []\n",
        "        for chunk in pd.read_csv(review_file, chunksize=chunk_size):\n",
        "            # Mantenemos solo columnas necesarias\n",
        "            chunk = chunk[['business_id', 'text']]\n",
        "\n",
        "            # Realizalisamos elel merge\n",
        "            merged_chunk = pd.merge(categoria_df, chunk, on=\"business_id\", how=\"inner\")\n",
        "\n",
        "            # Clasificacion de sentimientos en cada chunk\n",
        "            merged_chunk['sentiment'] = merged_chunk['text'].apply(clasificar_sentimiento)\n",
        "            processed_chunks.append(merged_chunk)\n",
        "\n",
        "        # Concatenanamos  todos los resultados de los chunks\n",
        "        final_df = pd.concat(processed_chunks, ignore_index=True)\n",
        "\n",
        "        # Guardamos resultados\n",
        "        output_path = os.path.join(output_dir, f\"{categoria_file.split('.')[0]}.csv\")\n",
        "        final_df.to_csv(output_path, index=False)\n",
        "        print(f\"Datos procesados y guardados en: {output_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error procesando {categoria_file}: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vsFoxdd5oQ6",
        "outputId": "63071ca6-fe0b-45d2-dba3-5db4f574ad32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando categoría: salud.csv...\n",
            "Datos procesados y guardados en: /content/categorias2/salud.csv\n",
            "Procesando categoría: otros.csv...\n",
            "Datos procesados y guardados en: /content/categorias2/otros.csv\n",
            "Procesando categoría: hoteles_y_hospedaje.csv...\n",
            "Datos procesados y guardados en: /content/categorias2/hoteles_y_hospedaje.csv\n",
            "Procesando categoría: restaurantes.csv...\n",
            "Datos procesados y guardados en: /content/categorias2/restaurantes.csv\n",
            "Procesando categoría: entretenimiento.csv...\n",
            "Datos procesados y guardados en: /content/categorias2/entretenimiento.csv\n",
            "Procesando categoría: supermercados_tiendas_negocios.csv...\n",
            "Datos procesados y guardados en: /content/categorias2/supermercados_tiendas_negocios.csv\n",
            "Procesando categoría: servicios_animales.csv...\n",
            "Datos procesados y guardados en: /content/categorias2/servicios_animales.csv\n",
            "Procesando categoría: educacion.csv...\n",
            "Datos procesados y guardados en: /content/categorias2/educacion.csv\n",
            "Procesando categoría: transporte.csv...\n",
            "Datos procesados y guardados en: /content/categorias2/transporte.csv\n",
            "Procesando categoría: servicios.csv...\n",
            "Datos procesados y guardados en: /content/categorias2/servicios.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "eliminamos filas repetidas repetidas"
      ],
      "metadata": {
        "id": "GaCpMTBN6ylM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los directorios\n",
        "input_dir = '/content/categorias2'\n",
        "output_dir = '/content/categorias2.5'\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Procesamos cada archivo en el directorio\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.endswith('.csv'):\n",
        "        input_path = os.path.join(input_dir, filename)\n",
        "        output_path = os.path.join(output_dir, filename)\n",
        "\n",
        "        df = pd.read_csv(input_path)\n",
        "\n",
        "        # Eliminamos filas duplicadas\n",
        "        df = df.drop_duplicates()\n",
        "\n",
        "        # Rellenamos datos vacíos con 'Null'\n",
        "        df = df.fillna('Null')\n",
        "\n",
        "        # Guardamos el archivo procesado\n",
        "        df.to_csv(output_path, index=False)\n",
        "\n",
        "        print(f\"Archivo procesado y guardado: {output_path}\")\n",
        "\n",
        "print(\"Todos los archivos han sido procesados y guardados en 'categorias2.5'.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFSRKV6A5HEW",
        "outputId": "91837b08-2a3c-453b-adb7-ffe8368fb9ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo procesado y guardado: /content/categorias2.5/salud.csv\n",
            "Archivo procesado y guardado: /content/categorias2.5/otros.csv\n",
            "Archivo procesado y guardado: /content/categorias2.5/hoteles_y_hospedaje.csv\n",
            "Archivo procesado y guardado: /content/categorias2.5/restaurantes.csv\n",
            "Archivo procesado y guardado: /content/categorias2.5/entretenimiento.csv\n",
            "Archivo procesado y guardado: /content/categorias2.5/supermercados_tiendas_negocios.csv\n",
            "Archivo procesado y guardado: /content/categorias2.5/servicios_animales.csv\n",
            "Archivo procesado y guardado: /content/categorias2.5/educacion.csv\n",
            "Archivo procesado y guardado: /content/categorias2.5/transporte.csv\n",
            "Archivo procesado y guardado: /content/categorias2.5/servicios.csv\n",
            "Todos los archivos han sido procesados y guardados en 'categorias2.5'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aumentamos el límite de tamaño de campo para evitar el error \"field larger\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "# Directorios de entrada y salida\n",
        "input_dir = \"/content/categorias2.5\"\n",
        "output_dir = \"/content/categorias3\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# establesemos el tamaño del chunk para evitar saturar la memoria\n",
        "chunk_size = 10000\n",
        "\n",
        "# Función para transformar y limpiar los datos por chunks\n",
        "def transformar_datos_por_chunks(input_file, output_file):\n",
        "    try:\n",
        "        with pd.read_csv(input_file, chunksize=chunk_size, engine='python', on_bad_lines='skip') as reader:\n",
        "            for i, chunk in enumerate(reader):\n",
        "                chunk.columns = [col.strip().lower() for col in chunk.columns]\n",
        "                if 'business_id' not in chunk.columns:\n",
        "                    chunk['business_id'] = None\n",
        "\n",
        "                # Cambiamos el nombre de las columnas a español para una mejor comprensión\n",
        "                chunk['nombre'] = chunk['name']\n",
        "                chunk['direccion'] = chunk['address']\n",
        "                chunk['ciudad'] = chunk['city']\n",
        "                chunk['estado'] = 'Florida'\n",
        "                chunk['codigo_postal'] = chunk['postal_code']\n",
        "                chunk['latitud'] = chunk['latitude']\n",
        "                chunk['longitud'] = chunk['longitude']\n",
        "                chunk['numero_de_reviews'] = chunk['review_count']\n",
        "                chunk['atributos'] = chunk['attributes']\n",
        "                chunk['categorias'] = chunk['categories']\n",
        "                chunk['puntuacion_usuarios'] = chunk['stars']\n",
        "                chunk['analisis_sentimientos'] = chunk['sentiment']\n",
        "                chunk['url_del_negocio'] = None\n",
        "                chunk['enlaces_google_maps'] = None\n",
        "                chunk['anio'] = chunk.get('date', 'Desconocido')  # Para evitar errores si falta 'date'\n",
        "\n",
        "                # Ordenamos las columnas\n",
        "                columnas_finales = [\n",
        "                    'business_id', 'nombre', 'direccion', 'ciudad', 'estado',\n",
        "                    'codigo_postal', 'latitud', 'longitud',\n",
        "                    'numero_de_reviews', 'atributos', 'categorias',\n",
        "                    'puntuacion_usuarios', 'analisis_sentimientos',\n",
        "                    'url_del_negocio', 'enlaces_google_maps', 'anio'\n",
        "                ]\n",
        "                chunk_final = chunk[columnas_finales]\n",
        "\n",
        "                # Guardamos cada chunk en el archivo de salida\n",
        "                mode = 'w' if i == 0 else 'a'\n",
        "                chunk_final.to_csv(output_file, index=False, mode=mode, header=(i == 0))\n",
        "                print(f\"Chunk {i+1} procesado y guardado para {output_file}.\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Error en el archivo {input_file}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error inesperado en el archivo {input_file}: {e}\")\n",
        "\n",
        "# Procesamos todos los archivos en la carpeta input_dir\n",
        "for file_name in os.listdir(input_dir):\n",
        "    if file_name.endswith('.csv'):\n",
        "        input_file = os.path.join(input_dir, file_name)\n",
        "        output_file = os.path.join(output_dir, file_name)\n",
        "        print(f\"Procesando {file_name}...\")\n",
        "        transformar_datos_por_chunks(input_file, output_file)\n",
        "\n",
        "print(\"Todos los archivos han sido procesados exitosamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QofedHbK4Ka",
        "outputId": "51d00793-c271-411d-ef13-c8829523bca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando salud.csv...\n",
            "Chunk 1 procesado y guardado para /content/categorias3/salud.csv.\n",
            "Chunk 2 procesado y guardado para /content/categorias3/salud.csv.\n",
            "Procesando otros.csv...\n",
            "Chunk 1 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 2 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 3 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 4 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 5 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 6 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 7 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 8 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 9 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 10 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 11 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 12 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 13 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 14 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 15 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 16 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 17 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 18 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 19 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 20 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 21 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 22 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Chunk 23 procesado y guardado para /content/categorias3/otros.csv.\n",
            "Procesando hoteles_y_hospedaje.csv...\n",
            "Chunk 1 procesado y guardado para /content/categorias3/hoteles_y_hospedaje.csv.\n",
            "Chunk 2 procesado y guardado para /content/categorias3/hoteles_y_hospedaje.csv.\n",
            "Chunk 3 procesado y guardado para /content/categorias3/hoteles_y_hospedaje.csv.\n",
            "Chunk 4 procesado y guardado para /content/categorias3/hoteles_y_hospedaje.csv.\n",
            "Chunk 5 procesado y guardado para /content/categorias3/hoteles_y_hospedaje.csv.\n",
            "Procesando restaurantes.csv...\n",
            "Chunk 1 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 2 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 3 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 4 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 5 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 6 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 7 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 8 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 9 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 10 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 11 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 12 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 13 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 14 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 15 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 16 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 17 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 18 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 19 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 20 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 21 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 22 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 23 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 24 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 25 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 26 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 27 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 28 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 29 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 30 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 31 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 32 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 33 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 34 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 35 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 36 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 37 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 38 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 39 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 40 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 41 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 42 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 43 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 44 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 45 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 46 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 47 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 48 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 49 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 50 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 51 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 52 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 53 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 54 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 55 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 56 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 57 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 58 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 59 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 60 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 61 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 62 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 63 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 64 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 65 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 66 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 67 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 68 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 69 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 70 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 71 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 72 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 73 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 74 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 75 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 76 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 77 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 78 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 79 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 80 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 81 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Chunk 82 procesado y guardado para /content/categorias3/restaurantes.csv.\n",
            "Procesando entretenimiento.csv...\n",
            "Chunk 1 procesado y guardado para /content/categorias3/entretenimiento.csv.\n",
            "Chunk 2 procesado y guardado para /content/categorias3/entretenimiento.csv.\n",
            "Procesando supermercados_tiendas_negocios.csv...\n",
            "Chunk 1 procesado y guardado para /content/categorias3/supermercados_tiendas_negocios.csv.\n",
            "Chunk 2 procesado y guardado para /content/categorias3/supermercados_tiendas_negocios.csv.\n",
            "Procesando servicios_animales.csv...\n",
            "Chunk 1 procesado y guardado para /content/categorias3/servicios_animales.csv.\n",
            "Procesando educacion.csv...\n",
            "Chunk 1 procesado y guardado para /content/categorias3/educacion.csv.\n",
            "Procesando transporte.csv...\n",
            "Chunk 1 procesado y guardado para /content/categorias3/transporte.csv.\n",
            "Procesando servicios.csv...\n",
            "Chunk 1 procesado y guardado para /content/categorias3/servicios.csv.\n",
            "Chunk 2 procesado y guardado para /content/categorias3/servicios.csv.\n",
            "Todos los archivos han sido procesados exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraemos los años en que fueron tomados los datos"
      ],
      "metadata": {
        "id": "r3HZMKEUgAVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorios de entrada y de salida\n",
        "input_dir = \"/content/categorias3\"\n",
        "output_dir = \"/content/categorias3.1\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Función para procesar un archivo\n",
        "def procesar_archivo(input_file, output_file):\n",
        "    df = pd.read_csv(input_file, low_memory=False)\n",
        "    filas_expandidas = []\n",
        "    for _, row in df.iterrows():\n",
        "        if pd.notna(row['anio']):\n",
        "            años = set(fecha.split('-')[0] for fecha in row['anio'].split(','))\n",
        "            for año in años:\n",
        "                nueva_fila = row.copy()\n",
        "                nueva_fila['anio'] = año\n",
        "                filas_expandidas.append(nueva_fila)\n",
        "        else:\n",
        "            filas_expandidas.append(row)\n",
        "\n",
        "    # Crearmos un nuevo DataFrame con las filas expandidas\n",
        "    df_expandidas = pd.DataFrame(filas_expandidas)\n",
        "\n",
        "    # Eliminamos duplicados\n",
        "    df_sin_duplicados = df_expandidas.drop_duplicates()\n",
        "\n",
        "    # Guardamos el archivo procesado\n",
        "    df_sin_duplicados.to_csv(output_file, index=False)\n",
        "    print(f\"Archivo procesado y guardado: {output_file}\")\n",
        "\n",
        "# Procesamos todos los archivos en el directorio\n",
        "for file_name in os.listdir(input_dir):\n",
        "    if file_name.endswith('.csv'):\n",
        "        input_file = os.path.join(input_dir, file_name)\n",
        "        output_file = os.path.join(output_dir, file_name)\n",
        "        print(f\"Procesando {file_name}...\")\n",
        "        procesar_archivo(input_file, output_file)\n",
        "\n",
        "print(\"Todos los archivos han sido procesados exitosamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQzlOVwJVlJs",
        "outputId": "1ccbc1fd-9a5a-408d-eff1-bdb3dc431f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando salud.csv...\n",
            "Archivo procesado y guardado: /content/categorias3.1/salud.csv\n",
            "Procesando otros.csv...\n",
            "Archivo procesado y guardado: /content/categorias3.1/otros.csv\n",
            "Procesando hoteles_y_hospedaje.csv...\n",
            "Archivo procesado y guardado: /content/categorias3.1/hoteles_y_hospedaje.csv\n",
            "Procesando restaurantes.csv...\n",
            "Archivo procesado y guardado: /content/categorias3.1/restaurantes.csv\n",
            "Procesando entretenimiento.csv...\n",
            "Archivo procesado y guardado: /content/categorias3.1/entretenimiento.csv\n",
            "Procesando supermercados_tiendas_negocios.csv...\n",
            "Archivo procesado y guardado: /content/categorias3.1/supermercados_tiendas_negocios.csv\n",
            "Procesando servicios_animales.csv...\n",
            "Archivo procesado y guardado: /content/categorias3.1/servicios_animales.csv\n",
            "Procesando educacion.csv...\n",
            "Archivo procesado y guardado: /content/categorias3.1/educacion.csv\n",
            "Procesando transporte.csv...\n",
            "Archivo procesado y guardado: /content/categorias3.1/transporte.csv\n",
            "Procesando servicios.csv...\n",
            "Archivo procesado y guardado: /content/categorias3.1/servicios.csv\n",
            "Todos los archivos han sido procesados exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mediante el archivo de dimenciones ciudades_dim otorgamos los datos corespondientes a ciudad y estado"
      ],
      "metadata": {
        "id": "vWcVn_l_hhe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para normalizar nombres\n",
        "def normalizar_nombre(nombre):\n",
        "    if pd.isna(nombre):\n",
        "        return nombre\n",
        "    nombre = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", str(nombre))\n",
        "    return nombre.strip().lower()\n",
        "\n",
        "# Función para corregir nombres específicos en la columna 'ciudad'\n",
        "def corregir_ciudad(ciudad):\n",
        "    if ciudad.lower() == \"st petersburg\":\n",
        "        return \"St. Petersburg\"\n",
        "    elif ciudad.lower() == \"tampa\":\n",
        "        return \"Tampa\"\n",
        "    elif ciudad.lower() == \"land o lakes\":\n",
        "        return \"Land O' Lakes\"\n",
        "    return ciudad\n",
        "\n",
        "# Rutas de los directorios de entrada y salida\n",
        "input_dir = \"/content/categorias3.1\"\n",
        "output_dir = \"/content/categorias3.2\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "unidades_dim_file = \"/content/sample_data/ciudades_dim.csv\"\n",
        "unidades_dim = pd.read_csv(unidades_dim_file)\n",
        "\n",
        "# Normalizamos y las columnas ciudad en anvos archivos\n",
        "unidades_dim['ciudad'] = unidades_dim['ciudad'].apply(corregir_ciudad)\n",
        "unidades_dim['ciudad_normalizada'] = unidades_dim['ciudad'].apply(normalizar_nombre)\n",
        "\n",
        "# Procesamos cada archivo en el directorio de entrada\n",
        "for file_name in os.listdir(input_dir):\n",
        "    if file_name.endswith('.csv'):\n",
        "        input_file = os.path.join(input_dir, file_name)\n",
        "        output_file = os.path.join(output_dir, file_name)\n",
        "        print(f\"Procesando {file_name}...\")\n",
        "        df = pd.read_csv(input_file, low_memory=False)\n",
        "        if 'ciudad' not in df.columns:\n",
        "            print(f\"Error: La columna 'ciudad' no existe en {file_name}.\")\n",
        "            continue\n",
        "        df['ciudad'] = df['ciudad'].apply(corregir_ciudad)\n",
        "        df['ciudad_normalizada'] = df['ciudad'].apply(normalizar_nombre)\n",
        "        df = pd.merge(\n",
        "            df,\n",
        "            unidades_dim,\n",
        "            how='left',\n",
        "            on='ciudad_normalizada',\n",
        "            suffixes=('', '_dim')\n",
        "        )\n",
        "        for col in ['id_condado', 'condado', 'codigo_postal_condado', 'latitud_condado',\n",
        "                    'longitud_condado', 'id_ciudad', 'codigo_postal_ciudad', 'latitud_ciudad',\n",
        "                    'longitud_ciudad']:\n",
        "            if col not in df.columns:\n",
        "                df[col] = None\n",
        "\n",
        "        # Ordenamos las columnas\n",
        "        columnas_ordenadas = [\n",
        "            'id_nombre', 'nombre', 'direccion', 'id_condado', 'condado',\n",
        "            'codigo_postal_condado', 'latitud_condado', 'longitud_condado',\n",
        "            'id_ciudad', 'ciudad', 'codigo_postal_ciudad', 'latitud_ciudad',\n",
        "            'longitud_ciudad', 'estado', 'atributos', 'categorias', 'puntuacion_usuarios',\n",
        "            'numero_de_reviews', 'analisis_sentimientos', 'url_del_negocio',\n",
        "            'enlaces_google_maps', 'anio'\n",
        "        ]\n",
        "\n",
        "        for col in columnas_ordenadas:\n",
        "            if col not in df.columns:\n",
        "                df[col] = None\n",
        "\n",
        "        df = df[columnas_ordenadas]\n",
        "\n",
        "        # Guardamos el archivo procesado\n",
        "        df.to_csv(output_file, index=False)\n",
        "        print(f\"Archivo procesado y guardado en: {output_file}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHXzWeEHEgPD",
        "outputId": "07bb8bb8-cfc6-467f-9655-9a566edaad0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando salud.csv...\n",
            "Archivo procesado y guardado en: /content/categorias3.2/salud.csv\n",
            "Procesando otros.csv...\n",
            "Archivo procesado y guardado en: /content/categorias3.2/otros.csv\n",
            "Procesando hoteles_y_hospedaje.csv...\n",
            "Archivo procesado y guardado en: /content/categorias3.2/hoteles_y_hospedaje.csv\n",
            "Procesando restaurantes.csv...\n",
            "Archivo procesado y guardado en: /content/categorias3.2/restaurantes.csv\n",
            "Procesando entretenimiento.csv...\n",
            "Archivo procesado y guardado en: /content/categorias3.2/entretenimiento.csv\n",
            "Procesando supermercados_tiendas_negocios.csv...\n",
            "Archivo procesado y guardado en: /content/categorias3.2/supermercados_tiendas_negocios.csv\n",
            "Procesando servicios_animales.csv...\n",
            "Archivo procesado y guardado en: /content/categorias3.2/servicios_animales.csv\n",
            "Procesando educacion.csv...\n",
            "Archivo procesado y guardado en: /content/categorias3.2/educacion.csv\n",
            "Procesando transporte.csv...\n",
            "Archivo procesado y guardado en: /content/categorias3.2/transporte.csv\n",
            "Procesando servicios.csv...\n",
            "Archivo procesado y guardado en: /content/categorias3.2/servicios.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otorgamos las ids corecpondiente mediante su archivo de dimenciones"
      ],
      "metadata": {
        "id": "XmUiKwHMjxe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para normalizar nombres\n",
        "def normalizar_nombre(nombre):\n",
        "    if pd.isna(nombre):\n",
        "        return nombre\n",
        "    nombre = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", str(nombre))  # Eliminar caracteres no alfanuméricos\n",
        "    return nombre.strip().lower()  # Convertir a minúsculas y eliminar espacios\n",
        "\n",
        "# Generamos ids alfanuméricos únicos de 5 dígitos\n",
        "def generar_id():\n",
        "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))\n",
        "\n",
        "# Cargamos las rutas de los archivos de entrada y salida\n",
        "input_file = \"/content/categorias3.2/educacion.csv\"\n",
        "output_file = \"/content/categorias3.3/educacion_ordenado.csv\"\n",
        "unidades_dim_file = \"/content/drive/MyDrive/data/datos_prosesados_limpios/unidades_educativas_dim.csv\"\n",
        "centros_educacion_dim_file = \"/content/categorias3.3/centros_educacion_dim.csv\"\n",
        "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Renombramos columna 'nombre' a 'centros_educativos'\n",
        "df.rename(columns={'nombre': 'centros_educativos'}, inplace=True)\n",
        "\n",
        "# Normalizamos los nombres\n",
        "df['centros_educativos_normalizado'] = df['centros_educativos'].apply(normalizar_nombre)\n",
        "\n",
        "# Creamos un DataFrame con nombres únicos de centros educativos\n",
        "centros_unicos = df[['centros_educativos_normalizado']].drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "# Generamos un id único para cada centro educativo\n",
        "centros_unicos['id_centros_educativos'] = centros_unicos['centros_educativos_normalizado'].apply(lambda x: generar_id())\n",
        "\n",
        "# Creamos el archivo centros_educacion_dim\n",
        "centros_educacion_dim = centros_unicos[['id_centros_educativos', 'centros_educativos_normalizado']].rename(\n",
        "    columns={'centros_educativos_normalizado': 'centros_educativos'}\n",
        ")\n",
        "centros_educacion_dim.to_csv(centros_educacion_dim_file, index=False)\n",
        "print(f\"Archivo centros_educacion_dim guardado en: {centros_educacion_dim_file}\")\n",
        "\n",
        "# Asignamos ids a los DataFrames originales\n",
        "id_centros_dict = dict(zip(centros_educacion_dim['centros_educativos'], centros_educacion_dim['id_centros_educativos']))\n",
        "df['id_centros_educativos'] = df['centros_educativos_normalizado'].map(id_centros_dict)\n",
        "\n",
        "# Revisamos  y eliminamos duplicados considerando  las columnas'centros_educativos' y 'anio'\n",
        "df = df.drop_duplicates(subset=['centros_educativos_normalizado', 'anio']).reset_index(drop=True)\n",
        "\n",
        "# Ordenamos las columnas\n",
        "columnas_ordenadas = [\n",
        "    'id_centros_educativos', 'centros_educativos', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado',\n",
        "    'id_ciudad', 'ciudad','codigo_postal_ciudad', 'latitud_ciudad', 'longitud_ciudad', 'estado', 'atributos', 'categorias', 'puntuacion_usuarios',\n",
        "    'numero_de_reviews', 'analisis_sentimientos', 'url_del_negocio',\n",
        "    'enlaces_google_maps', 'anio'\n",
        "]\n",
        "for col in columnas_ordenadas:\n",
        "    if col not in df.columns:\n",
        "        df[col] = None\n",
        "\n",
        "df = df[columnas_ordenadas]\n",
        "\n",
        "# Agrupamos por 'anio'\n",
        "df = df.sort_values(by=['anio', 'centros_educativos'])\n",
        "\n",
        "# Guardamos el archivo procesado agrupado por 'anio'\n",
        "df.to_csv(output_file, index=False)\n",
        "print(f\"Archivo procesado y guardado en: {output_file}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmx9gBBeb587",
        "outputId": "f158574c-599e-4f2c-c596-7b523f1f848b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo centros_educacion_dim guardado en: /content/categorias3.3/centros_educacion_dim.csv\n",
            "Archivo procesado y guardado en: /content/categorias3.3/educacion_ordenado.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otorgamos las ids corecpondiente mediante su archivo de dimenciones"
      ],
      "metadata": {
        "id": "muQ4yv-Qj-G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para normalizar nombres\n",
        "def normalizar_nombre(nombre):\n",
        "    if pd.isna(nombre):\n",
        "        return nombre\n",
        "    nombre = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", str(nombre))\n",
        "    return nombre.strip().lower()\n",
        "\n",
        "# Generamos un ids alfanuméricos únicos de 5 dígitos\n",
        "def generar_id():\n",
        "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))\n",
        "\n",
        "# Cargamos los archivos de entrada y de salida\n",
        "input_file = \"/content/categorias3.2/entretenimiento.csv\"\n",
        "output_file = \"/content/categorias3.3/entretenimiento_ordenado.csv\"\n",
        "centros_educacion_dim_file = \"/content/categorias3.3/centros_entretenimiento_dim.csv\"\n",
        "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "df = pd.read_csv(input_file)\n",
        "df.rename(columns={'nombre': 'centros_entretenimiento'}, inplace=True)\n",
        "\n",
        "# Normalizar nombres\n",
        "df['centros_entretenimiento_normalizado'] = df['centros_entretenimiento'].apply(normalizar_nombre)\n",
        "centros_unicos = df[['centros_entretenimiento_normalizado']].drop_duplicates().reset_index(drop=True)\n",
        "centros_unicos['id_centros_entretenimiento'] = centros_unicos['centros_entretenimiento_normalizado'].apply(lambda x: generar_id())\n",
        "centros_entretenimiento_dim = centros_unicos[['id_centros_entretenimiento', 'centros_entretenimiento_normalizado']].rename(\n",
        "    columns={'centros_entretenimiento_normalizado': 'centros_entretenimiento'}\n",
        ")\n",
        "centros_entretenimiento_dim.to_csv(centros_educacion_dim_file, index=False)\n",
        "print(f\"Archivo centros_entretenimiento_dim guardado en: {centros_educacion_dim_file}\")\n",
        "\n",
        "# Asignamos las ids a los DataFrames originales\n",
        "id_centros_dict = dict(zip(centros_entretenimiento_dim['centros_entretenimiento'], centros_entretenimiento_dim['id_centros_entretenimiento']))\n",
        "df['id_centros_entretenimiento'] = df['centros_entretenimiento_normalizado'].map(id_centros_dict)\n",
        "\n",
        "# Revisamos y eliminamos duplicados considerando  las columnas'centros_entretenimiento' y 'anio'\n",
        "if 'anio' in df.columns:\n",
        "    df = df.drop_duplicates(subset=['centros_entretenimiento_normalizado', 'anio']).reset_index(drop=True)\n",
        "else:\n",
        "    print(\"Advertencia: La columna 'anio' no existe en el archivo de entrada.\")\n",
        "\n",
        "# Ordenamos las columnas\n",
        "columnas_ordenadas = [\n",
        "    'id_centros_entretenimiento', 'centros_entretenimiento', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado',\n",
        "    'id_ciudad', 'ciudad', 'latitud_ciudad','codigo_postal_ciudad', 'longitud_ciudad','estado', 'atributos', 'categorias', 'puntuacion_usuarios',\n",
        "    'numero_de_reviews', 'analisis_sentimientos', 'url_del_negocio',\n",
        "    'enlaces_google_maps', 'anio'\n",
        "]\n",
        "for col in columnas_ordenadas:\n",
        "    if col not in df.columns:\n",
        "        df[col] = None\n",
        "\n",
        "df = df[columnas_ordenadas]\n",
        "df = df.sort_values(by=['anio', 'centros_entretenimiento'])\n",
        "\n",
        "# Guardamos el archivo procesado agrupado por 'anio'\n",
        "df.to_csv(output_file, index=False)\n",
        "print(f\"Archivo procesado y guardado en: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvBGUrO8Fon2",
        "outputId": "358344be-3f18-46bb-dd5a-9436f85f63db"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo centros_entretenimiento_dim guardado en: /content/categorias3.3/centros_entretenimiento_dim.csv\n",
            "Archivo procesado y guardado en: /content/categorias3.3/entretenimiento_ordenado.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otorgamos las ids corecpondiente mediante su archivo de dimenciones"
      ],
      "metadata": {
        "id": "3vU20VHrj_fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para normalizar nombres\n",
        "def normalizar_nombre(nombre):\n",
        "    if pd.isna(nombre):\n",
        "        return nombre\n",
        "    nombre = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", str(nombre))\n",
        "    return nombre.strip().lower()\n",
        "\n",
        "# Generamos ids alfanuméricos únicos de 5 dígitos\n",
        "def generar_id():\n",
        "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))\n",
        "\n",
        "#Cargamos los archivos de entrada y salida\n",
        "input_file = \"/content/categorias3.2/hoteles_y_hospedaje.csv\"\n",
        "output_file = \"/content/categorias3.3/hosteleria_ordenado.csv\"\n",
        "centros_hosteleria_dim_file = \"/content/categorias3.3/centros_hosteleria_dim.csv\"\n",
        "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "df = pd.read_csv(input_file)\n",
        "df.rename(columns={'nombre': 'centros_hosteleria'}, inplace=True)\n",
        "\n",
        "# Normalizamos los nombres\n",
        "df['centros_hosteleria_normalizado'] = df['centros_hosteleria'].apply(normalizar_nombre)\n",
        "centros_unicos = df[['centros_hosteleria_normalizado']].drop_duplicates().reset_index(drop=True)\n",
        "centros_unicos['id_centros_hosteleria'] = centros_unicos['centros_hosteleria_normalizado'].apply(lambda x: generar_id())\n",
        "centros_hosteleria_dim = centros_unicos[['id_centros_hosteleria', 'centros_hosteleria_normalizado']].rename(\n",
        "    columns={'centros_hosteleria_normalizado': 'centros_hosteleria'}\n",
        ")\n",
        "centros_hosteleria_dim.to_csv(centros_hosteleria_dim_file, index=False)\n",
        "print(f\"Archivo centros_hosteleria_dim guardado en: {centros_hosteleria_dim_file}\")\n",
        "id_centros_dict = dict(zip(centros_hosteleria_dim['centros_hosteleria'], centros_hosteleria_dim['id_centros_hosteleria']))\n",
        "df['id_centros_hosteleria'] = df['centros_hosteleria_normalizado'].map(id_centros_dict)\n",
        "if 'anio' in df.columns:\n",
        "    df = df.drop_duplicates(subset=['centros_hosteleria_normalizado', 'anio']).reset_index(drop=True)\n",
        "else:\n",
        "    print(\"Advertencia: La columna 'anio' no existe en el archivo de entrada.\")\n",
        "    df = df.drop_duplicates(subset=['centros_hosteleria_normalizado']).reset_index(drop=True)\n",
        "\n",
        "#Ordenamos las columnas\n",
        "columnas_ordenadas = [\n",
        "    'id_centros_hosteleria', 'centros_hosteleria', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado',\n",
        "    'id_ciudad', 'ciudad','codigo_postal_ciudad',  'latitud_ciudad', 'longitud_ciudad','estado', 'atributos', 'categorias', 'puntuacion_usuarios',\n",
        "    'numero_de_reviews', 'analisis_sentimientos', 'url_del_negocio',\n",
        "    'enlaces_google_maps', 'anio'\n",
        "]\n",
        "\n",
        "for col in columnas_ordenadas:\n",
        "    if col not in df.columns:\n",
        "        df[col] = None\n",
        "df = df[columnas_ordenadas]\n",
        "if 'anio' in df.columns:\n",
        "    df = df.sort_values(by=['anio', 'centros_hosteleria'])\n",
        "\n",
        "# Guardamos el archivo procesado agrupado por 'anio'\n",
        "df.to_csv(output_file, index=False)\n",
        "print(f\"Archivo procesado y guardado en: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcVOt-g2IBCK",
        "outputId": "02b9ec45-e3d6-4b3c-d085-91fe2f3cde79"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo centros_hosteleria_dim guardado en: /content/categorias3.3/centros_hosteleria_dim.csv\n",
            "Archivo procesado y guardado en: /content/categorias3.3/hosteleria_ordenado.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otorgamos las ids corecpondiente mediante su archivo de dimenciones"
      ],
      "metadata": {
        "id": "3Troc1zSkA6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para normalizar nombres\n",
        "def normalizar_nombre(nombre):\n",
        "    if pd.isna(nombre):\n",
        "        return nombre\n",
        "    nombre = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", str(nombre))\n",
        "    return nombre.strip().lower()\n",
        "\n",
        "# Generamos ids  alfanuméricos únicos de 5 dígitos\n",
        "def generar_id():\n",
        "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))\n",
        "\n",
        "#Cargamos los archivos de entrada y salida\n",
        "input_file = \"/content/categorias3.2/restaurantes.csv\"\n",
        "output_file = \"/content/categorias3.3/restaurantes_ordenado.csv\"\n",
        "centros_restaurantes_dim_file = \"/content/categorias3.3/centros_restaurantes_dim.csv\"\n",
        "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "df = pd.read_csv(input_file)\n",
        "df.rename(columns={'nombre': 'centros_restaurantes'}, inplace=True)\n",
        "\n",
        "# Normalizamos los  nombres\n",
        "df['centros_restaurantes_normalizado'] = df['centros_restaurantes'].apply(normalizar_nombre)\n",
        "centros_unicos = df[['centros_restaurantes_normalizado']].drop_duplicates().reset_index(drop=True)\n",
        "centros_unicos['id_centros_restaurantes'] = centros_unicos['centros_restaurantes_normalizado'].apply(lambda x: generar_id())\n",
        "centros_restaurantes_dim = centros_unicos[['id_centros_restaurantes', 'centros_restaurantes_normalizado']].rename(\n",
        "    columns={'centros_restaurantes_normalizado': 'centros_restaurantes'}\n",
        ")\n",
        "centros_restaurantes_dim.to_csv(centros_restaurantes_dim_file, index=False)\n",
        "print(f\"Archivo centros_restaurantes_dim guardado en: {centros_restaurantes_dim_file}\")\n",
        "id_centros_dict = dict(zip(centros_restaurantes_dim['centros_restaurantes'], centros_restaurantes_dim['id_centros_restaurantes']))\n",
        "df['id_centros_restaurantes'] = df['centros_restaurantes_normalizado'].map(id_centros_dict)\n",
        "\n",
        "if 'anio' in df.columns:\n",
        "    df = df.drop_duplicates(subset=['centros_restaurantes_normalizado', 'anio']).reset_index(drop=True)\n",
        "else:\n",
        "    print(\"Advertencia: La columna 'anio' no existe en el archivo de entrada.\")\n",
        "    df = df.drop_duplicates(subset=['centros_restaurantes_normalizado']).reset_index(drop=True)\n",
        "\n",
        "# Ordenamos las columnas\n",
        "columnas_ordenadas = [\n",
        "    'id_centros_restaurantes', 'centros_restaurantes', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado',\n",
        "    'id_ciudad', 'ciudad', 'codigo_postal_ciudad', 'latitud_ciudad', 'longitud_ciudad','estado', 'atributos', 'categorias', 'puntuacion_usuarios',\n",
        "    'numero_de_reviews', 'analisis_sentimientos', 'url_del_negocio',\n",
        "    'enlaces_google_maps', 'anio'\n",
        "]\n",
        "\n",
        "for col in columnas_ordenadas:\n",
        "    if col not in df.columns:\n",
        "        df[col] = None\n",
        "\n",
        "df = df[columnas_ordenadas]\n",
        "if 'anio' in df.columns:\n",
        "    df = df.sort_values(by=['anio', 'centros_restaurantes'])\n",
        "\n",
        "# Guardamos el archivo procesado agrupado por 'anio'\n",
        "df.to_csv(output_file, index=False)\n",
        "print(f\"Archivo procesado y guardado en: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlnifSZSSu4b",
        "outputId": "4d83f278-65b1-4e22-b7cc-bb55d1d104c7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo centros_restaurantes_dim guardado en: /content/categorias3.3/centros_restaurantes_dim.csv\n",
            "Archivo procesado y guardado en: /content/categorias3.3/restaurantes_ordenado.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otorgamos las ids corecpondiente mediante su archivo de dimenciones"
      ],
      "metadata": {
        "id": "W4HXKI5FkCQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Función para normalizar nombres\n",
        "def normalizar_nombre(nombre):\n",
        "    if pd.isna(nombre):\n",
        "        return nombre\n",
        "    nombre = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", str(nombre))  # Eliminar caracteres no alfanuméricos\n",
        "    return nombre.strip().lower()  # Convertir a minúsculas y eliminar espacios\n",
        "\n",
        "# Generamos ids alfanuméricos únicos de 5 dígitos\n",
        "def generar_id():\n",
        "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))\n",
        "\n",
        "# Cargamos las rutas de los archivos de entrada y de salida\n",
        "input_file = \"/content/categorias3.2/supermercados_tiendas_negocios.csv\"\n",
        "output_file = \"/content/categorias3.3/servicio_tiendas_negocio_ordenado.csv\"\n",
        "centros_tiendas_negocio_dim_file = \"/content/categorias3.3/servicio_tiendas_negocio_dim.csv\"\n",
        "\n",
        "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "df = pd.read_csv(input_file)\n",
        "df.rename(columns={'nombre': 'centros_tiendas_negocio'}, inplace=True)\n",
        "df['centros_tiendas_negocio_normalizado'] = df['centros_tiendas_negocio'].apply(normalizar_nombre)\n",
        "\n",
        "centros_unicos = df[['centros_tiendas_negocio_normalizado']].drop_duplicates().reset_index(drop=True)\n",
        "centros_unicos['id_centros_tiendas_negocio'] = centros_unicos['centros_tiendas_negocio_normalizado'].apply(lambda x: generar_id())\n",
        "centros_tiendas_negocio_dim = centros_unicos[['id_centros_tiendas_negocio', 'centros_tiendas_negocio_normalizado']].rename(\n",
        "    columns={'centros_tiendas_negocio_normalizado': 'centros_tiendas_negocio'}\n",
        ")\n",
        "centros_tiendas_negocio_dim.to_csv(centros_tiendas_negocio_dim_file, index=False)\n",
        "print(f\"Archivo servicio_tiendas_negocio_dim guardado en: {centros_tiendas_negocio_dim_file}\")\n",
        "\n",
        "id_centros_dict = dict(zip(centros_tiendas_negocio_dim['centros_tiendas_negocio'], centros_tiendas_negocio_dim['id_centros_tiendas_negocio']))\n",
        "df['id_centros_tiendas_negocio'] = df['centros_tiendas_negocio_normalizado'].map(id_centros_dict)\n",
        "\n",
        "# Revisamos y eliminamos duplicados considerando  las columnas'centros_tiendas_negocio' y 'anio'\n",
        "if 'anio' in df.columns:\n",
        "    df = df.drop_duplicates(subset=['centros_tiendas_negocio_normalizado', 'anio']).reset_index(drop=True)\n",
        "else:\n",
        "    print(\"Advertencia: La columna 'anio' no existe en el archivo de entrada.\")\n",
        "    df = df.drop_duplicates(subset=['centros_tiendas_negocio_normalizado']).reset_index(drop=True)\n",
        "\n",
        "# Ordenamos las columnas\n",
        "columnas_ordenadas = [\n",
        "    'id_centros_tiendas_negocio', 'centros_tiendas_negocio', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado',\n",
        "    'id_ciudad', 'ciudad', 'codigo_postal_ciudad','latitud_ciudad', 'longitud_ciudad', 'estado', 'atributos', 'categorias', 'puntuacion_usuarios',\n",
        "    'numero_de_reviews', 'analisis_sentimientos', 'url_del_negocio',\n",
        "    'enlaces_google_maps', 'anio'\n",
        "]\n",
        "\n",
        "for col in columnas_ordenadas:\n",
        "    if col not in df.columns:\n",
        "        df[col] = None\n",
        "\n",
        "df = df[columnas_ordenadas]\n",
        "\n",
        "if 'anio' in df.columns:\n",
        "    df = df.sort_values(by=['anio', 'centros_tiendas_negocio'])\n",
        "\n",
        "# Guardamos el archivo procesado agrupado por 'anio'\n",
        "df.to_csv(output_file, index=False)\n",
        "print(f\"Archivo procesado y guardado en: {output_file}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lOR20POVs2Z",
        "outputId": "c742736a-eacf-40fc-cee0-beed6f380eff"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo servicio_tiendas_negocio_dim guardado en: /content/categorias3.3/servicio_tiendas_negocio_dim.csv\n",
            "Archivo procesado y guardado en: /content/categorias3.3/servicio_tiendas_negocio_ordenado.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otorgamos las ids corecpondiente mediante su archivo de dimenciones"
      ],
      "metadata": {
        "id": "wjhBkhfMkFZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para normalizar nombres\n",
        "def normalizar_nombre(nombre):\n",
        "    if pd.isna(nombre):\n",
        "        return nombre\n",
        "    nombre = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", str(nombre))  # Eliminar caracteres no alfanuméricos\n",
        "    return nombre.strip().lower()  # Convertir a minúsculas y eliminar espacios\n",
        "\n",
        "# Generamos ids alfanuméricos únicos de 5 dígitos\n",
        "def generar_id():\n",
        "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))\n",
        "\n",
        "# cargamos las rutas de los archivos\n",
        "input_file = \"/content/categorias3.2/transporte.csv\"\n",
        "output_file = \"/content/categorias3.3/servicio_transporte_ordenado.csv\"\n",
        "centros_transporte_dim_file = \"/content/categorias3.3/servicio_transporte_dim.csv\"\n",
        "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "df.rename(columns={'nombre': 'transporte'}, inplace=True)\n",
        "\n",
        "# Normalizamos los nombres\n",
        "df['centros_transporte_normalizado'] = df['transporte'].apply(normalizar_nombre)\n",
        "\n",
        "centros_unicos = df[['centros_transporte_normalizado']].drop_duplicates().reset_index(drop=True)\n",
        "centros_unicos['id_transporte'] = centros_unicos['centros_transporte_normalizado'].apply(lambda x: generar_id())\n",
        "\n",
        "# Creamos el archivo servicio_transporte_dim sin nombres repetidos\n",
        "centros_transporte_dim = centros_unicos[['id_transporte', 'centros_transporte_normalizado']].rename(\n",
        "    columns={'centros_transporte_normalizado': 'transporte'}\n",
        ")\n",
        "centros_transporte_dim.to_csv(centros_transporte_dim_file, index=False)\n",
        "print(f\"Archivo servicio_transporte_dim guardado en: {centros_transporte_dim_file}\")\n",
        "id_centros_dict = dict(zip(centros_transporte_dim['transporte'], centros_transporte_dim['id_transporte']))\n",
        "df['id_transporte'] = df['centros_transporte_normalizado'].map(id_centros_dict)\n",
        "if 'anio' in df.columns:\n",
        "    df = df.drop_duplicates(subset=['centros_transporte_normalizado', 'anio']).reset_index(drop=True)\n",
        "else:\n",
        "    print(\"Advertencia: La columna 'anio' no existe en el archivo de entrada.\")\n",
        "    df = df.drop_duplicates(subset=['centros_transporte_normalizado']).reset_index(drop=True)\n",
        "\n",
        "# Organisamos las columnas\n",
        "columnas_ordenadas = [\n",
        "    'id_transporte', 'transporte', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado',\n",
        "    'id_ciudad', 'ciudad', 'codigo_postal_ciudad', 'latitud_ciudad', 'longitud_ciudad','estado', 'atributos', 'categorias', 'puntuacion_usuarios',\n",
        "    'numero_de_reviews', 'analisis_sentimientos', 'url_del_negocio',\n",
        "    'enlaces_google_maps', 'anio'\n",
        "]\n",
        "for col in columnas_ordenadas:\n",
        "    if col not in df.columns:\n",
        "        df[col] = None\n",
        "df = df[columnas_ordenadas]\n",
        "if 'anio' in df.columns:\n",
        "    df = df.sort_values(by=['anio', 'transporte'])\n",
        "\n",
        "# Guardamos el archivo procesado agrupado por 'anio'\n",
        "df.to_csv(output_file, index=False)\n",
        "print(f\"Archivo procesado y guardado en: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8j92ztqXTaA",
        "outputId": "4518a595-7539-40cf-ac94-35ecfbe106f1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo servicio_transporte_dim guardado en: /content/categorias3.3/servicio_transporte_dim.csv\n",
            "Archivo procesado y guardado en: /content/categorias3.3/servicio_transporte_ordenado.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Ruta de origen y destino\n",
        "origen = \"/content/categorias3.3\"\n",
        "destino = \"/content/drive/MyDrive/categorias3.3\"\n",
        "\n",
        "# Verificar si el destino existe y eliminarlo si es necesario\n",
        "if os.path.exists(destino):\n",
        "    shutil.rmtree(destino)  # Eliminar el directorio existente\n",
        "\n",
        "# Mover el directorio\n",
        "shutil.move(origen, destino)\n",
        "\n",
        "print(f\"Directorio movido de {origen} a {destino}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRMsQTxPtaoL",
        "outputId": "249962a0-1674-4e36-f118-3c1e57120d93"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directorio movido de /content/categorias3.3 a /content/drive/MyDrive/categorias3.3\n"
          ]
        }
      ]
    }
  ]
}