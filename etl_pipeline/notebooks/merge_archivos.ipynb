{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Una  ves emos echo la limpieza de los datos provenientes de YELP , Google y Overpass procederemos hacer un merge entre los datos para simplificar los archivos."
      ],
      "metadata": {
        "id": "0V6lVTlXjNAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq7tsJvtjN7Z",
        "outputId": "e59b8e82-3074-45c4-eacb-b9de5c04b1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Librerias\n",
        "import pandas as pd\n",
        "import unidecode\n",
        "import os\n",
        "import random\n",
        "import string"
      ],
      "metadata": {
        "id": "lg3yumJNjVZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Realizamos un merge con los datos  del servicio de entretenimiento obtenidos de Overpass"
      ],
      "metadata": {
        "id": "eavwPQeREhl0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ocd-wM2Dln6Z",
        "outputId": "c0151956-1074-4283-cd3e-be8bafd4bd21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo combinado guardado en: /content/sample_data/Parques_de_diversiones_Centros_comerciales_combined.csv\n"
          ]
        }
      ],
      "source": [
        "# Listamos los  archivos que se encuentran separados por años a combinar\n",
        "files = [\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/Parques_de_diversiones_Centros_comerciales csv/Parques_de_diversiones_Centros_comerciales_2014.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/Parques_de_diversiones_Centros_comerciales csv/Parques_de_diversiones_Centros_comerciales_2015.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/Parques_de_diversiones_Centros_comerciales csv/Parques_de_diversiones_Centros_comerciales_2016.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/Parques_de_diversiones_Centros_comerciales csv/Parques_de_diversiones_Centros_comerciales_2017.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/Parques_de_diversiones_Centros_comerciales csv/Parques_de_diversiones_Centros_comerciales_2018.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/Parques_de_diversiones_Centros_comerciales csv/Parques_de_diversiones_Centros_comerciales_2019.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/Parques_de_diversiones_Centros_comerciales csv/Parques_de_diversiones_Centros_comerciales_2020.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/Parques_de_diversiones_Centros_comerciales csv/Parques_de_diversiones_Centros_comerciales_2021.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/Parques_de_diversiones_Centros_comerciales csv/Parques_de_diversiones_Centros_comerciales_2022.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/Parques_de_diversiones_Centros_comerciales csv/Parques_de_diversiones_Centros_comerciales_2023.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/Parques_de_diversiones_Centros_comerciales csv/Parques_de_diversiones_Centros_comerciales_2024.csv'\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "for file in files:\n",
        "    if os.path.exists(file):\n",
        "        df = pd.read_csv(file)\n",
        "        dfs.append(df)\n",
        "    else:\n",
        "        print(f\"El archivo no existe: {file}\")\n",
        "\n",
        "# Realisamos un merge con los archivos listados\n",
        "merged_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Guardamos el archivo\n",
        "output_path = '/content/sample_data/Parques_de_diversiones_Centros_comerciales_combined.csv'\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Archivo combinado guardado en: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al archivo obtenido anteriormente mediante el archivos dimensiones procedamos a completar  los datos de condado  y id del establecimiento"
      ],
      "metadata": {
        "id": "0WnLDy-OHe4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los archivos de entrada\n",
        "combined_file = '/content/sample_data/Parques_de_diversiones_Centros_comerciales_combined.csv'\n",
        "ciudades_dim_file = '/content/sample_data/ciudades_dim.csv'\n",
        "centros_entretenimiento_dim_file = '/content/drive/MyDrive/categorias3.3/centros_entretenimiento_dim.csv'\n",
        "\n",
        "combined_df = pd.read_csv(combined_file)\n",
        "ciudades_dim = pd.read_csv(ciudades_dim_file)\n",
        "centros_entretenimiento_dim = pd.read_csv(centros_entretenimiento_dim_file)\n",
        "\n",
        "#Nos asegurar que las columnas ids sean de tipo string\n",
        "ciudades_dim['id_ciudad'] = ciudades_dim['id_ciudad'].astype(str)\n",
        "ciudades_dim['id_condado'] = ciudades_dim['id_condado'].astype(str)\n",
        "combined_df['id_ciudad'] = combined_df['id_ciudad'].astype(str)\n",
        "centros_entretenimiento_dim['id_centros_entretenimiento'] = centros_entretenimiento_dim['id_centros_entretenimiento'].astype(str)\n",
        "\n",
        "# Cambiamos el nombre de la columna 'nombre' a 'centros_entretenimiento'\n",
        "if 'nombre' in combined_df.columns:\n",
        "    combined_df.rename(columns={'nombre': 'centros_entretenimiento'}, inplace=True)\n",
        "\n",
        "# Normalizamos las columnas con nombres para evitar signos o letras en mayusculas\n",
        "def normalizar_nombre(nombre):\n",
        "    if pd.isnull(nombre):\n",
        "        return None\n",
        "    return unidecode.unidecode(str(nombre)).lower().strip()\n",
        "\n",
        "combined_df['ciudad_norm'] = combined_df['ciudad'].apply(normalizar_nombre)\n",
        "ciudades_dim['ciudad_norm'] = ciudades_dim['ciudad'].apply(normalizar_nombre)\n",
        "combined_df['centros_entretenimiento_normalizado'] = combined_df['centros_entretenimiento'].apply(normalizar_nombre)\n",
        "centros_entretenimiento_dim['centros_entretenimiento_normalizado'] = centros_entretenimiento_dim['centros_entretenimiento'].apply(normalizar_nombre)\n",
        "\n",
        "# Realizamos el merge para completar datos faltantes\n",
        "merged_df = combined_df.merge(\n",
        "    ciudades_dim[['ciudad_norm', 'id_ciudad', 'id_condado', 'condado',\n",
        "                  'codigo_postal_condado', 'latitud_condado', 'longitud_condado',\n",
        "                  'codigo_postal_ciudad', 'latitud_ciudad', 'longitud_ciudad']],\n",
        "    on='ciudad_norm',\n",
        "    how='left',\n",
        "    suffixes=('', '_ciudad_dim')\n",
        ")\n",
        "\n",
        "if 'id_ciudad' not in merged_df.columns:\n",
        "    print(\"Error: La columna 'id_ciudad' no se encontró después del merge.\")\n",
        "else:\n",
        "    print(\"La columna 'id_ciudad' se asignó correctamente.\")\n",
        "\n",
        "missing_id_ciudad = merged_df['id_ciudad'].isnull().sum()\n",
        "if missing_id_ciudad > 0:\n",
        "    print(f\"Registros sin id_ciudad: {missing_id_ciudad}\")\n",
        "    merged_df[merged_df['id_ciudad'].isnull()].to_csv('/content/sample_data/registros_sin_id_ciudad.csv', index=False)\n",
        "    print(\"Registros sin id_ciudad guardados en: /content/sample_data/registros_sin_id_ciudad.csv\")\n",
        "\n",
        "# Asignamos id a  la columna centros de entretenimiento y agregamos nuevos nombres si no existen en el archivo dim\n",
        "def generar_id_unico(existentes):\n",
        "    while True:\n",
        "        nuevo_id = ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))\n",
        "        if nuevo_id not in existentes:\n",
        "            return nuevo_id\n",
        "\n",
        "ids_existentes = set(centros_entretenimiento_dim['id_centros_entretenimiento'])\n",
        "nuevas_unidades = []\n",
        "\n",
        "for index, row in merged_df.iterrows():\n",
        "    nombre_norm = row['centros_entretenimiento_normalizado']\n",
        "    matching_row = centros_entretenimiento_dim[centros_entretenimiento_dim['centros_entretenimiento_normalizado'] == nombre_norm]\n",
        "\n",
        "    if not matching_row.empty:\n",
        "        merged_df.at[index, 'id_centros_entretenimiento'] = matching_row['id_centros_entretenimiento'].values[0]\n",
        "    else:\n",
        "        nuevo_id = generar_id_unico(ids_existentes)\n",
        "        ids_existentes.add(nuevo_id)\n",
        "        merged_df.at[index, 'id_centros_entretenimiento'] = nuevo_id\n",
        "        nuevas_unidades.append({\n",
        "            'id_centros_entretenimiento': nuevo_id,\n",
        "            'centros_entretenimiento': row['centros_entretenimiento'],\n",
        "            'centros_entretenimiento_normalizado': nombre_norm\n",
        "        })\n",
        "\n",
        "# Agregamos nuevos datos al archivo dim\n",
        "if nuevas_unidades:\n",
        "    nuevas_unidades_df = pd.DataFrame(nuevas_unidades)\n",
        "    centros_entretenimiento_dim = pd.concat([centros_entretenimiento_dim, nuevas_unidades_df], ignore_index=True)\n",
        "    centros_entretenimiento_dim.drop(columns=['centros_entretenimiento_normalizado'], inplace=True)\n",
        "    centros_entretenimiento_dim.to_csv(centros_entretenimiento_dim_file, index=False)\n",
        "    print(f\"Se han añadido {len(nuevas_unidades)} nuevos centros de entretenimiento al archivo de referencia.\")\n",
        "\n",
        "# organisamos las columnas\n",
        "ordered_columns = [\n",
        "    'id_centros_entretenimiento', 'centros_entretenimiento', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado', 'id_ciudad', 'ciudad', 'codigo_postal_ciudad',\n",
        "    'latitud_ciudad', 'longitud_ciudad', 'estado', 'atributos', 'categorias', 'puntuacion_usuarios',\n",
        "    'numero_de_reviews', 'analisis_sentimientos', 'url_del_negocio', 'enlaces_google_maps', 'anio'\n",
        "]\n",
        "\n",
        "for col in ordered_columns:\n",
        "    if col not in merged_df.columns:\n",
        "        merged_df[col] = None\n",
        "\n",
        "merged_df = merged_df[ordered_columns]\n",
        "\n",
        "# Guardamos el archivo procesado final\n",
        "output_path = '/content/sample_data/Parques_de_diversiones_Centros_comerciales_final.csv'\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Archivo procesado y guardado en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSZQdVjDpamU",
        "outputId": "84533ad7-73c7-40e2-c8fa-55176d45801a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La columna 'id_ciudad' se asignó correctamente.\n",
            "Archivo procesado y guardado en: /content/sample_data/Parques_de_diversiones_Centros_comerciales_final.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cambiamos los nombres de columnas para que queden iguales en todos los archivos"
      ],
      "metadata": {
        "id": "joBqo76hI3_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del archivo de entrada y salida\n",
        "input_file = '/content/drive/MyDrive/categorias10/servicios_entretenimiento.csv'\n",
        "output_file = '/content/drive/MyDrive/categorias10/servicios_entretenimiento_coregido.csv'\n",
        "\n",
        "# Cargar el archivo\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Renombrar las columnas según lo solicitado\n",
        "column_renames = {\n",
        "    'atributo': 'atributos',\n",
        "    'categoria': 'categorias',\n",
        "    '.url': 'url_del_negocio',\n",
        "    'ranquing_por_usuario': 'puntuacion_usuarios'\n",
        "\n",
        "}\n",
        "\n",
        "df.rename(columns=column_renames, inplace=True)\n",
        "\n",
        "# Guardar el archivo actualizado\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Archivo actualizado guardado en: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9Ai6oeeI3SE",
        "outputId": "65ac8e9a-c7df-45e8-a01e-26a925484acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo actualizado guardado en: /content/drive/MyDrive/categorias10/servicios_entretenimiento_coregido.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unificamos los archivos obtenidos  de Google Yelp y Overpass"
      ],
      "metadata": {
        "id": "7NMry9ouQRRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos la ruta de los archivos que vamos a usar en el merge\n",
        "\n",
        "file1 = '/content/sample_data/Parques_de_diversiones_Centros_comerciales_final.csv'\n",
        "file2 = '/content/drive/MyDrive/categorias3.3/entretenimiento_ordenado.csv'\n",
        "file3 = '/content/drive/MyDrive/categorias10/servicios_entretenimiento_coregido.csv'\n",
        "\n",
        "df1 = pd.read_csv(file1)\n",
        "df2 = pd.read_csv(file2)\n",
        "df3 = pd.read_csv(file3)\n",
        "\n",
        "# Agregamos una columna de categoría general \"Entretenimiento\" en cada archivo\n",
        "\n",
        "df1['categoria_general'] = 'Entretenimiento'\n",
        "df2['categoria_general'] = 'Entretenimiento'\n",
        "df3['categoria_general'] = 'Entretenimiento'\n",
        "\n",
        "# Realizamos el merge de los tres archivos\n",
        "\n",
        "merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "print(\"Columnas disponibles después del merge:\", merged_df.columns)\n",
        "\n",
        "if {'centros_entretenimiento', 'anio', 'latitud_ciudad'}.issubset(merged_df.columns):\n",
        "    merged_df['non_null_count'] = merged_df.notna().sum(axis=1)\n",
        "    merged_df = merged_df.sort_values(by='non_null_count', ascending=False)\n",
        "    merged_df = merged_df.drop_duplicates(subset=['centros_entretenimiento', 'anio', 'latitud_ciudad'], keep='first')\n",
        "    merged_df = merged_df.drop(columns=['non_null_count'], errors='ignore')  #\n",
        "else:\n",
        "    print(\"Las columnas necesarias para resolver duplicados no están presentes en el DataFrame.\")\n",
        "\n",
        "# Ordenamos los datos por la columna 'anio' de menor a mayor\n",
        "if 'anio' in merged_df.columns:\n",
        "    merged_df = merged_df.sort_values(by='anio', ascending=True)\n",
        "\n",
        "# Guardamos  el resultado\n",
        "output_path = '/content/sample_data/servicios_entretenimiento_combinado.csv'\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Archivo combinado con categoría general 'Entretenimiento', sin duplicados y ordenado guardado en: {output_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2OGEJCA87se",
        "outputId": "d4fa9168-adf6-4ae2-fe2a-0e841f56c63e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas disponibles después del merge: Index(['id_centros_entretenimiento', 'centros_entretenimiento', 'direccion',\n",
            "       'id_condado', 'condado', 'codigo_postal_condado', 'latitud_condado',\n",
            "       'longitud_condado', 'id_ciudad', 'ciudad', 'codigo_postal_ciudad',\n",
            "       'latitud_ciudad', 'longitud_ciudad', 'estado', 'atributos',\n",
            "       'categorias', 'puntuacion_usuarios', 'numero_de_reviews',\n",
            "       'analisis_sentimientos', 'url_del_negocio', 'enlaces_google_maps',\n",
            "       'anio', 'categoria_general', 'url'],\n",
            "      dtype='object')\n",
            "Archivo combinado con categoría general 'Entretenimiento', sin duplicados y ordenado guardado en: /content/sample_data/servicios_entretenimiento_combinado.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminamos signos inesesarios"
      ],
      "metadata": {
        "id": "fqZIya7hTdv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Archivo de entrada y salida\n",
        "input_file = '/content/sample_data/servicios_entretenimiento_combinado.csv'\n",
        "output_file = '/content/sample_data/servicios_entretenimiento_combinado_formateado.csv'\n",
        "\n",
        "# Cargar el archivo\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Normalizar nombres de columnas (sin transformar \"&\")\n",
        "df.columns = [\n",
        "    col_name.strip()\n",
        "    .replace(\" \", \"_\")\n",
        "    .replace(\"& \", \"and\")\n",
        "    .replace(\",\", \"\")\n",
        "    .replace(\"(\", \"\")\n",
        "    .replace(\")\", \"\")\n",
        "    .replace(\"$\", \"\")\n",
        "    .replace(\";\", \"\")\n",
        "    .replace(\"=\", \"\")\n",
        "    .replace(\".\", \"_\")\n",
        "    .replace(\"\\n\", \"\")\n",
        "    .replace(\"\\t\", \"\")\n",
        "    for col_name in df.columns\n",
        "]\n",
        "\n",
        "# Asignar tipos de datos a las columnas según lo solicitado\n",
        "column_types = {\n",
        "    'id_centros_entretenimiento': 'string',\n",
        "    'centros_entretenimiento': 'string',\n",
        "    'direccion': 'string',\n",
        "    'id_condado': 'string',\n",
        "    'condado': 'string',\n",
        "    'codigo_postal_condado': 'string',\n",
        "    'latitud_condado': 'float',\n",
        "    'longitud_condado': 'float',\n",
        "    'id_ciudad': 'string',\n",
        "    'ciudad': 'string',\n",
        "    'codigo_postal_ciudad': 'string',\n",
        "    'latitud_ciudad': 'float',\n",
        "    'longitud_ciudad': 'float',\n",
        "    'estado': 'string',\n",
        "    'categorias': 'string',\n",
        "    'puntuacion_usuarios': 'float',\n",
        "    'analisis_sentimientos': 'string',\n",
        "    'url_del_negocio': 'string',\n",
        "    'enlaces_google_maps': 'string',\n",
        "    'anio': 'int'\n",
        "}\n",
        "\n",
        "# Aplicar tipos de datos\n",
        "for column, dtype in column_types.items():\n",
        "    if column in df.columns:\n",
        "        df[column] = df[column].astype(dtype)\n",
        "\n",
        "# Eliminar caracteres no deseados en todas las columnas de tipo string\n",
        "columns_to_clean = df.select_dtypes(include=['string']).columns\n",
        "df[columns_to_clean] = df[columns_to_clean].replace(\n",
        "    to_replace=r\"[\\[\\]\\{\\}'\\\"]\", value=\"\", regex=True\n",
        ")\n",
        "\n",
        "\n",
        "# Guardar el archivo procesado\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Archivo procesado y guardado en: {output_file}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USzVD3jlq2Ge",
        "outputId": "3c5a21f1-09a8-4c59-f186-bfd6376e8c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo procesado y guardado en: /content/sample_data/servicios_entretenimiento_combinado_formateado.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos un merge con los datos  del servicio de entretenimiento obtenidos de Overpass"
      ],
      "metadata": {
        "id": "OKOWn4fkT_2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Listamos los archivos a combinar\n",
        "files = [\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/unidad educativa csv/unidad_educativa_2014.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/unidad educativa csv/unidad_educativa_2015.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/unidad educativa csv/unidad_educativa_2016.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/unidad educativa csv/unidad_educativa_2017.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/unidad educativa csv/unidad_educativa_2018.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/unidad educativa csv/unidad_educativa_2019.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/unidad educativa csv/unidad_educativa_2020.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/unidad educativa csv/unidad_educativa_2021.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/unidad educativa csv/unidad_educativa_2022.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/unidad educativa csv/unidad_educativa_2023.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/unidad educativa csv/unidad_educativa_2044.csv',\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "for file in files:\n",
        "    if os.path.exists(file):\n",
        "        df = pd.read_csv(file)\n",
        "        dfs.append(df)\n",
        "    else:\n",
        "        print(f\"El archivo no existe: {file}\")\n",
        "\n",
        "# Concatenamos todos los DataFrames\n",
        "merged_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Guardamos el archivo combinado\n",
        "output_path = '/content/unidad_educativa_combined.csv'\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Archivo combinado guardado en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTLQuvreuPwi",
        "outputId": "74e486fe-a8e2-4c4a-e1d6-bc9f81a8e5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El archivo no existe: /content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/unidad educativa csv/unidad_educativa_2044.csv\n",
            "Archivo combinado guardado en: /content/unidad_educativa_combined.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos aseguramos que loas columnas tegan en el archivo combinado y el archivo dim  ,los mismosnombres"
      ],
      "metadata": {
        "id": "Y2SuUIEuUYQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos la ruta del archivo dim\n",
        "centros_educacion_dim_file = '/content/drive/MyDrive/categorias3.3/centros_educacion_dim.csv'\n",
        "centros_educacion_dim = pd.read_csv(centros_educacion_dim_file)\n",
        "\n",
        "# Renombramos  las columnas\n",
        "centros_educacion_dim.rename(columns={\n",
        "    'id_centros_educativos': 'id_centros_educacion',\n",
        "    'centros_educativos': 'centros_educacion'\n",
        "}, inplace=True)\n",
        "\n",
        "# Guardamos los cambios\n",
        "centros_educacion_dim.to_csv(centros_educacion_dim_file, index=False)\n",
        "\n",
        "print(f\"Archivo actualizado y guardado en: {centros_educacion_dim_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxoCGr_RveWK",
        "outputId": "4f537c88-31be-4a1e-f4da-98555a77f3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo actualizado y guardado en: /content/drive/MyDrive/categorias3.3/centros_educacion_dim.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del archivo de entrada y salida\n",
        "input_file = '/content/drive/MyDrive/categorias10/servicios_educacion.csv'\n",
        "output_file = '/content/drive/MyDrive/categorias10/servicios_educacion_coregido.csv'\n",
        "\n",
        "# Cargar el archivo\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Renombrar las columnas según lo solicitado\n",
        "column_renames = {\n",
        "    'atributo': 'atributos',\n",
        "    'categoria': 'categorias',\n",
        "    '.url': 'url_del_negocio',\n",
        "    'ranquing_por_usuario': 'puntuacion_usuarios'\n",
        "\n",
        "}\n",
        "\n",
        "df.rename(columns=column_renames, inplace=True)\n",
        "\n",
        "# Guardar el archivo actualizado\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Archivo actualizado guardado en: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQomdmIjY2NJ",
        "outputId": "95488f48-be6a-41ee-a62b-c07019548acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo actualizado guardado en: /content/drive/MyDrive/categorias10/servicios_educacion_coregido.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Completamos archivos faltantes mediante los archivos de dimenciones"
      ],
      "metadata": {
        "id": "8R4ZuqneVPLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los archivos nesesrios para el merge\n",
        "combined_file = '/content/unidad_educativa_combined.csv'\n",
        "ciudades_dim_file = '/content/sample_data/ciudades_dim.csv'\n",
        "centros_educacion_dim_file = '/content/drive/MyDrive/categorias3.3/centros_educacion_dim.csv'\n",
        "\n",
        "combined_df = pd.read_csv(combined_file)\n",
        "ciudades_dim = pd.read_csv(ciudades_dim_file)\n",
        "centros_educacion_dim = pd.read_csv(centros_educacion_dim_file)\n",
        "\n",
        "# Revisamos que el formato sea igual en las columnas nesesarias\n",
        "\n",
        "ciudades_dim['id_ciudad'] = ciudades_dim['id_ciudad'].astype(str)\n",
        "ciudades_dim['id_condado'] = ciudades_dim['id_condado'].astype(str)\n",
        "combined_df['id_ciudad'] = combined_df['id_ciudad'].astype(str)\n",
        "centros_educacion_dim['id_centros_educacion'] = centros_educacion_dim['id_centros_educacion'].astype(str)\n",
        "\n",
        "# Cambiamos  el nombre de la columna 'nombre' a 'centros_educacion' si existe\n",
        "if 'nombre' in combined_df.columns:\n",
        "    combined_df.rename(columns={'nombre': 'centros_educacion'}, inplace=True)\n",
        "\n",
        "# Normalizamos las columnas a usar\n",
        "def normalizar_nombre(nombre):\n",
        "    if pd.isnull(nombre):\n",
        "        return None\n",
        "    return unidecode.unidecode(str(nombre)).lower().strip()\n",
        "\n",
        "combined_df['ciudad_norm'] = combined_df['ciudad'].apply(normalizar_nombre)\n",
        "ciudades_dim['ciudad_norm'] = ciudades_dim['ciudad'].apply(normalizar_nombre)\n",
        "combined_df['centros_educacion_normalizado'] = combined_df['centros_educacion'].apply(normalizar_nombre)\n",
        "centros_educacion_dim['centros_educacion_normalizado'] = centros_educacion_dim['centros_educacion'].apply(normalizar_nombre)\n",
        "\n",
        "# Realizamos el merge para completar la información de la ciudad\n",
        "merged_df = combined_df.merge(\n",
        "    ciudades_dim[['ciudad_norm', 'id_ciudad', 'id_condado', 'condado',\n",
        "                  'codigo_postal_condado', 'latitud_condado', 'longitud_condado',\n",
        "                  'codigo_postal_ciudad', 'latitud_ciudad', 'longitud_ciudad']],\n",
        "    on='ciudad_norm',\n",
        "    how='left',\n",
        "    suffixes=('', '_ciudad_dim')\n",
        ")\n",
        "\n",
        "if 'id_ciudad' not in merged_df.columns:\n",
        "    print(\"Error: La columna 'id_ciudad' no se encontró después del merge.\")\n",
        "else:\n",
        "    print(\"La columna 'id_ciudad' se asignó correctamente.\")\n",
        "\n",
        "missing_id_ciudad = merged_df['id_ciudad'].isnull().sum()\n",
        "if missing_id_ciudad > 0:\n",
        "    print(f\"Registros sin id_ciudad: {missing_id_ciudad}\")\n",
        "    merged_df[merged_df['id_ciudad'].isnull()].to_csv('/content/sample_data/registros_sin_id_ciudad.csv', index=False)\n",
        "    print(\"Registros sin id_ciudad guardados en: /content/sample_data/registros_sin_id_ciudad.csv\")\n",
        "\n",
        "# Asignamos las ids a centros de educacion y agregar nuevos nombres si no existen en el archivo dim\n",
        "def generar_id_unico(existentes):\n",
        "    while True:\n",
        "        nuevo_id = ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))\n",
        "        if nuevo_id not in existentes:\n",
        "            return nuevo_id\n",
        "\n",
        "ids_existentes = set(centros_educacion_dim['id_centros_educacion'])\n",
        "nuevas_unidades = []\n",
        "\n",
        "for index, row in merged_df.iterrows():\n",
        "    nombre_norm = row['centros_educacion_normalizado']\n",
        "    matching_row = centros_educacion_dim[centros_educacion_dim['centros_educacion_normalizado'] == nombre_norm]\n",
        "\n",
        "    if not matching_row.empty:\n",
        "        merged_df.at[index, 'id_centros_educacion'] = matching_row['id_centros_educacion'].values[0]\n",
        "    else:\n",
        "        nuevo_id = generar_id_unico(ids_existentes)\n",
        "        ids_existentes.add(nuevo_id)\n",
        "        merged_df.at[index, 'id_centros_educacion'] = nuevo_id\n",
        "        nuevas_unidades.append({\n",
        "            'id_centros_educacion': nuevo_id,\n",
        "            'centros_educacion': row['centros_educacion'],\n",
        "            'centros_educacion_normalizado': nombre_norm\n",
        "        })\n",
        "\n",
        "if nuevas_unidades:\n",
        "    nuevas_unidades_df = pd.DataFrame(nuevas_unidades)\n",
        "    centros_educacion_dim = pd.concat([centros_educacion_dim, nuevas_unidades_df], ignore_index=True)\n",
        "    centros_educacion_dim.drop(columns=['centros_educacion_normalizado'], inplace=True)\n",
        "    centros_educacion_dim.to_csv(centros_educacion_dim_file, index=False)\n",
        "    print(f\"Se han añadido {len(nuevas_unidades)} nuevos centros de educación al archivo de referencia.\")\n",
        "\n",
        "# ordenamos las columnas\n",
        "ordered_columns = [\n",
        "    'id_centros_educacion', 'centros_educacion', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado', 'id_ciudad', 'ciudad', 'codigo_postal_ciudad',\n",
        "    'latitud_ciudad', 'longitud_ciudad', 'estado', 'atributos', 'categorias', 'puntuacion_usuarios',\n",
        "    'numero_de_reviews', 'analisis_sentimientos', 'url_del_negocio', 'enlaces_google_maps', 'anio'\n",
        "]\n",
        "for col in ordered_columns:\n",
        "    if col not in merged_df.columns:\n",
        "        merged_df[col] = None\n",
        "\n",
        "merged_df = merged_df[ordered_columns]\n",
        "\n",
        "# Guardamos el archivo procesado\n",
        "output_path = '/content/sample_data/servicios_educacion2_final.csv'\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Archivo procesado y guardado en: {output_path}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YtoKWlTv31P",
        "outputId": "2d44ab3e-2c3c-462d-f247-cc54b37c7db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La columna 'id_ciudad' se asignó correctamente.\n",
            "Archivo procesado y guardado en: /content/sample_data/servicios_educacion2_final.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminamos en la columna ciudad el nombre de Dania ya que la ciudad no esta definida"
      ],
      "metadata": {
        "id": "QI4Adwb3aras"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el archivo\n",
        "file_path = '/content/sample_data/servicios_educacion2_final.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "filtered_data = data[data['ciudad'] != 'Dania']\n",
        "\n",
        "# Guardamos el resultado\n",
        "output_path = '/content/sample_data/servicios_educacion2_filtered.csv'\n",
        "filtered_data.to_csv(output_path, index=False)\n",
        "\n",
        "output_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hReOBDPDvrYh",
        "outputId": "bd7139f8-a4f4-4a14-ebfe-1dc65a191704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/sample_data/servicios_educacion2_filtered.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unificamos los archivos obtenidos  de Google Yelp y Overpass"
      ],
      "metadata": {
        "id": "98f6PQCZkRsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los archivos nesesarios para el merge\n",
        "file1 = '/content/sample_data/servicios_educacion2_filtered.csv'\n",
        "file2 = '/content/drive/MyDrive/categorias3.3/educacion_ordenado.csv'\n",
        "file3 = '/content/drive/MyDrive/categorias10/servicios_educacion_coregido.csv'\n",
        "\n",
        "df1 = pd.read_csv(file1)\n",
        "df2 = pd.read_csv(file2)\n",
        "df3 = pd.read_csv(file3)\n",
        "\n",
        "# Agregamos una columna de categoría general \"educacion\"\n",
        "df1['categoria_general'] = 'educacion'\n",
        "df2['categoria_general'] = 'educacion'\n",
        "df3['categoria_general'] = 'educacion'\n",
        "\n",
        "required_columns = [\n",
        "    'id_centros_educacion', 'centros_educacion', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado', 'id_ciudad', 'ciudad',\n",
        "    'codigo_postal_ciudad', 'latitud_ciudad', 'longitud_ciudad', 'estado', 'atributos',\n",
        "    'categorias', 'puntuacion_usuarios', 'numero_de_reviews', 'analisis_sentimientos',\n",
        "    'url_del_negocio', 'enlaces_google_maps', 'anio', 'categoria_general'\n",
        "]\n",
        "for df in [df1, df2, df3]:\n",
        "    for col in required_columns:\n",
        "        if col not in df.columns:\n",
        "            df[col] = pd.NA\n",
        "\n",
        "# Realisamos el merge\n",
        "merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "\n",
        "# eliminamos filas duplicadas\n",
        "\n",
        "if {'centros_educacion', 'anio', 'latitud_ciudad'}.issubset(merged_df.columns):\n",
        "    merged_df['non_null_count'] = merged_df.notna().sum(axis=1)\n",
        "    merged_df = merged_df.sort_values(by='non_null_count', ascending=False)\n",
        "    merged_df = merged_df.drop_duplicates(subset=['centros_educacion', 'anio', 'latitud_ciudad'], keep='first')\n",
        "    merged_df = merged_df.drop(columns=['non_null_count'], errors='ignore')\n",
        "\n",
        "# Ordenamos los datos por la columna 'anio'\n",
        "if 'anio' in merged_df.columns:\n",
        "    merged_df = merged_df.sort_values(by='anio', ascending=True)\n",
        "\n",
        "# Guardamos el resultado\n",
        "output_path = '/content/sample_data/servicios_educacion_combinado2.csv'\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Archivo combinado con categoría general 'Educacion', sin duplicados y ordenado guardado en: {output_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qway_W_xwR38",
        "outputId": "69822c7c-1e13-4bd4-abc8-be43e7de4d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo combinado con categoría general 'Educacion', sin duplicados y ordenado guardado en: /content/sample_data/servicios_educacion_combinado2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ordenamos las columnas"
      ],
      "metadata": {
        "id": "V7wmBHERlFaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el oreden de las columnas\n",
        "columns_to_keep = [\n",
        "    'id_centros_educacion', 'centros_educacion', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado', 'id_ciudad', 'ciudad',\n",
        "    'codigo_postal_ciudad', 'latitud_ciudad', 'longitud_ciudad', 'estado', 'atributos',\n",
        "    'categorias', 'puntuacion_usuarios', 'numero_de_reviews', 'analisis_sentimientos',\n",
        "    'url_del_negocio', 'enlaces_google_maps', 'categoria_general', 'anio'\n",
        "]\n",
        "\n",
        "\n",
        "file_path = '/content/sample_data/servicios_educacion2_final.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "if 'categoria_general' not in data.columns:\n",
        "    data['categoria_general'] = 'educacion'\n",
        "\n",
        "filtered_data = data[data['ciudad'] != 'Dania']\n",
        "\n",
        "final_data = filtered_data[columns_to_keep]\n",
        "\n",
        "# Guardamos el resultado\n",
        "output_path = '/content/sample_data/servicios_educacion2_final_filtered.csv'\n",
        "final_data.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Archivo procesado guardado en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwbWlBv_xbMZ",
        "outputId": "ccf2b5f5-a2e4-48ee-b97e-5ebd2bdecf21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo procesado guardado en: /content/sample_data/servicios_educacion2_final_filtered.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminamos los caracteres imnesesarios"
      ],
      "metadata": {
        "id": "P7HUhSIGlZTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos los archivos de  entrada y salida\n",
        "input_file = '/content/sample_data/servicios_educacion2_final_filtered.csv'\n",
        "output_file = '/content/sample_data/servicios_educacion2_final_filtered2.csv.csv'\n",
        "\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Normalizamos nombres de columnas\n",
        "df.columns = [\n",
        "    col_name.strip()\n",
        "    .replace(\" \", \"_\")\n",
        "    .replace(\",\", \"\")\n",
        "    .replace(\"(\", \"\")\n",
        "    .replace(\")\", \"\")\n",
        "    .replace(\"$\", \"\")\n",
        "    .replace(\";\", \"\")\n",
        "    .replace(\"=\", \"\")\n",
        "    .replace(\".\", \"_\")\n",
        "    .replace(\"\\n\", \"\")\n",
        "    .replace(\"\\t\", \"\")\n",
        "    for col_name in df.columns\n",
        "]\n",
        "\n",
        "# Asignamos el formato de los tipos de datos a las columnas\n",
        "column_types = {\n",
        "    'id_centros_entretenimiento': 'string',\n",
        "    'centros_entretenimiento': 'string',\n",
        "    'direccion': 'string',\n",
        "    'id_condado': 'string',\n",
        "    'condado': 'string',\n",
        "    'codigo_postal_condado': 'string',\n",
        "    'latitud_condado': 'float',\n",
        "    'longitud_condado': 'float',\n",
        "    'id_ciudad': 'string',\n",
        "    'ciudad': 'string',\n",
        "    'codigo_postal_ciudad': 'string',\n",
        "    'latitud_ciudad': 'float',\n",
        "    'longitud_ciudad': 'float',\n",
        "    'estado': 'string',\n",
        "    'categorias': 'string',\n",
        "    'puntuacion_usuarios': 'float',\n",
        "    'analisis_sentimientos': 'string',\n",
        "    'url_del_negocio': 'string',\n",
        "    'enlaces_google_maps': 'string',\n",
        "    'anio': 'int'\n",
        "}\n",
        "\n",
        "for column, dtype in column_types.items():\n",
        "    if column in df.columns:\n",
        "        df[column] = df[column].astype(dtype)\n",
        "\n",
        "# Eliminamos caracteres no deseados en todas las columnas de tipo string\n",
        "columns_to_clean = df.select_dtypes(include=['string']).columns\n",
        "df[columns_to_clean] = df[columns_to_clean].replace(\n",
        "    to_replace=r\"[\\[\\]\\{\\}'\\\"]\", value=\"\", regex=True\n",
        ")\n",
        "\n",
        "\n",
        "# Guardamos el archivo procesado\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Archivo procesado y guardado en: {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cJyvtJix9m4",
        "outputId": "de61c81f-0d4d-46e5-d8bd-b7ef29723c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo procesado y guardado en: /content/sample_data/servicios_educacion2_final_filtered2.csv.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7Iyaw2qzxuxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZRCzHlJphCBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cambiamos los nombres de colunas en los archivos dim y servicios restaurantes"
      ],
      "metadata": {
        "id": "1bp6d07Vl8YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos la ruta del archivo\n",
        "file_path = '/content/drive/MyDrive/categorias3.3/servicios_restaurantes_dim.csv'\n",
        "o\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "df.rename(columns={'id_centros_restaurantes': 'id_servicios_restaurantes',\n",
        "                   'centros_restaurantes': 'servicios_restaurantes'}, inplace=True)\n",
        "\n",
        "# Guardamos el archivo actualizado\n",
        "df.to_csv(file_path, index=False)\n",
        "\n",
        "\"Las columnas han sido renombradas y el archivo actualizado correctamente.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Rnoej0at3HPZ",
        "outputId": "55910899-b89d-41c7-93e1-188a90d7d439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Las columnas han sido renombradas y el archivo actualizado correctamente.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Realizamos un merge con los datos  del servicio restaurantes  obtenidos de Overpass"
      ],
      "metadata": {
        "id": "L0zJ6kEQpL5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos archivos de entrada\n",
        "files = [\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/restaurantes csv/restaurantes_2023.csv',\n",
        "    '/content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/restaurantes csv/restaurant_turvo_2022.csv'\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for file in files:\n",
        "    if os.path.exists(file):\n",
        "        df = pd.read_csv(file)\n",
        "        print(f\"Columnas originales en {file}: {list(df.columns)}\")\n",
        "\n",
        "        if 'nombre' in df.columns:\n",
        "            df.rename(columns={'nombre': 'servicio_restaurantes'}, inplace=True)\n",
        "        else:\n",
        "            print(f\"La columna 'nombre' no existe en el archivo: {file}. Se omite este archivo.\")\n",
        "            continue\n",
        "\n",
        "        if 'id_nombre' in df.columns:\n",
        "            df.drop(columns=['id_nombre'], inplace=True)\n",
        "\n",
        "        dfs.append(df)\n",
        "    else:\n",
        "        print(f\"El archivo no existe: {file}\")\n",
        "\n",
        "if len(dfs) == 0:\n",
        "    print(\"No se encontraron archivos válidos para combinar.\")\n",
        "    exit()\n",
        "\n",
        "# Realizamos el merge\n",
        "merged_df = pd.concat(dfs, ignore_index=True)\n",
        "print(f\"Columnas después de concatenar: {list(merged_df.columns)}\")\n",
        "\n",
        "# Cargamos la ruta del archivo de servicios_restaurantes_dim y otorgamos las id correspondientes\n",
        "servicios_dim_file = '/content/drive/MyDrive/categorias3.3/servicios_restaurantes_dim.csv'\n",
        "if os.path.exists(servicios_dim_file):\n",
        "    servicios_dim = pd.read_csv(servicios_dim_file)\n",
        "    print(f\"Columnas en servicios_restaurantes_dim: {list(servicios_dim.columns)}\")\n",
        "    servicios_dim.rename(columns={'servicios_restaurantes': 'servicio_restaurantes'}, inplace=True)\n",
        "\n",
        "    servicios_dict = dict(zip(servicios_dim['servicio_restaurantes'], servicios_dim['id_servicios_restaurantes']))\n",
        "\n",
        "    merged_df['id_servicio_restaurantes'] = merged_df['servicio_restaurantes'].map(servicios_dict)\n",
        "\n",
        "    for index, row in merged_df[merged_df['id_servicio_restaurantes'].isnull()].iterrows():\n",
        "        new_id = ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))\n",
        "        servicios_dict[row['servicio_restaurantes']] = new_id\n",
        "        merged_df.at[index, 'id_servicio_restaurantes'] = new_id\n",
        "\n",
        "    nuevos_servicios = merged_df[~merged_df['servicio_restaurantes'].isin(servicios_dim['servicio_restaurantes'])]\n",
        "    if not nuevos_servicios.empty:\n",
        "        nuevos_registros = nuevos_servicios[['servicio_restaurantes', 'id_servicio_restaurantes']].drop_duplicates()\n",
        "        nuevos_registros.to_csv(servicios_dim_file, mode='a', index=False, header=False)\n",
        "else:\n",
        "    print(f\"El archivo de servicios no existe: {servicios_dim_file}\")\n",
        "    exit()\n",
        "\n",
        "# Guardamos el archivo combinado\n",
        "output_path = '/content/restaurantes_combined.csv'\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "print(f\"Archivo combinado guardado en: {output_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPYveP8yyxbo",
        "outputId": "76d155c6-c030-4459-feb7-8c90789200f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas originales en /content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/restaurantes csv/restaurantes_2023.csv: ['id_nombre', 'nombre', 'direccion', 'id_ciudad', 'ciudad', 'estado', 'pais', 'codigo_postal', 'longitud', 'latitud', 'anio']\n",
            "Columnas originales en /content/drive/MyDrive/data/Datos Procesados-20250109T140622Z-001/Datos Procesados/restaurantes csv/restaurant_turvo_2022.csv: ['id_nombre', 'nombre', 'direccion', 'id_ciudad', 'ciudad', 'estado', 'pais', 'codigo_postal', 'longitud', 'latitud', 'anio']\n",
            "Columnas después de concatenar: ['servicio_restaurantes', 'direccion', 'id_ciudad', 'ciudad', 'estado', 'pais', 'codigo_postal', 'longitud', 'latitud', 'anio']\n",
            "Columnas en servicios_restaurantes_dim: ['id_servicios_restaurantes', 'servicios_restaurantes']\n",
            "Archivo combinado guardado en: /content/restaurantes_combined.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ponemos los datos de condado"
      ],
      "metadata": {
        "id": "1tBJAs04qC4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos las rutas de los archivos\n",
        "combined_file = '/content/restaurantes_combined.csv'\n",
        "ciudades_dim_file = '/content/sample_data/ciudades_dim.csv'\n",
        "combined_df = pd.read_csv(combined_file)\n",
        "ciudades_dim = pd.read_csv(ciudades_dim_file)\n",
        "\n",
        "# Renombramos las columnas en combined_df\n",
        "combined_df.rename(columns={\n",
        "    'latitud': 'latitud_ciudad',\n",
        "    'longitud': 'longitud_ciudad',\n",
        "    'codigo_postal': 'codigo_postal_ciudad'\n",
        "}, inplace=True)\n",
        "\n",
        "# Normalizamos las claves en ambos DataFrames\n",
        "for col in ['id_ciudad', 'ciudad', 'codigo_postal_ciudad']:\n",
        "    combined_df[col] = combined_df[col].astype(str).str.strip().str.lower()\n",
        "    ciudades_dim[col] = ciudades_dim[col].astype(str).str.strip().str.lower()\n",
        "ciudades_dim = ciudades_dim.assign(\n",
        "    codigo_postal_ciudad=ciudades_dim['codigo_postal_ciudad'].str.split(',')\n",
        ").explode('codigo_postal_ciudad').reset_index(drop=True)\n",
        "\n",
        "ciudades_dim['codigo_postal_ciudad'] = ciudades_dim['codigo_postal_ciudad'].str.strip().str.lower()\n",
        "\n",
        "print(\"\\nClaves únicas en combined_df:\")\n",
        "print(combined_df[['id_ciudad', 'ciudad', 'codigo_postal_ciudad']].drop_duplicates().head(10))\n",
        "\n",
        "print(\"\\nClaves únicas en ciudades_dim:\")\n",
        "print(ciudades_dim[['id_ciudad', 'ciudad', 'codigo_postal_ciudad']].drop_duplicates().head(10))\n",
        "\n",
        "merged_df = combined_df.merge(\n",
        "    ciudades_dim[['id_condado', 'condado', 'codigo_postal_condado', 'latitud_condado', 'longitud_condado',\n",
        "                  'id_ciudad', 'ciudad', 'codigo_postal_ciudad']],\n",
        "    on=['id_ciudad', 'ciudad', 'codigo_postal_ciudad'],\n",
        "    how='left'\n",
        ")\n",
        "print(\"\\nDatos faltantes en columnas relacionadas con el condado:\")\n",
        "print(merged_df[['id_condado', 'condado', 'codigo_postal_condado', 'latitud_condado', 'longitud_condado']].isnull().sum())\n",
        "\n",
        "unmatched_rows = merged_df[merged_df['id_condado'].isnull()]\n",
        "print(\"\\nFilas sin coincidencia (primeras 10):\")\n",
        "print(unmatched_rows[['id_ciudad', 'ciudad', 'codigo_postal_ciudad']].head(10))\n",
        "\n",
        "unmatched_rows.to_csv('/content/unmatched_rows.csv', index=False)\n",
        "print(\"\\nFilas sin coincidencias guardadas en: /content/unmatched_rows.csv\")\n",
        "\n",
        "if 'id_servicios_restaurantes' not in merged_df.columns:\n",
        "    merged_df['id_servicios_restaurantes'] = combined_df['id_servicio_restaurantes']\n",
        "if 'servicios_restaurantes' not in merged_df.columns:\n",
        "    merged_df['servicios_restaurantes'] = combined_df['servicio_restaurantes']\n",
        "\n",
        "# Ordenamos las columnas\n",
        "ordered_columns = [\n",
        "    'id_servicios_restaurantes', 'servicios_restaurantes', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado', 'id_ciudad', 'ciudad', 'codigo_postal_ciudad',\n",
        "    'latitud_ciudad', 'longitud_ciudad', 'estado', 'atributos', 'categorias', 'puntuacion_usuarios',\n",
        "    'numero_de_reviews', 'analisis_sentimientos', 'url_del_negocio', 'enlaces_google_maps', 'anio'\n",
        "]\n",
        "\n",
        "for col in ordered_columns:\n",
        "    if col not in merged_df.columns:\n",
        "        merged_df[col] = None\n",
        "\n",
        "merged_df = merged_df[ordered_columns]\n",
        "\n",
        "# Guardamos el archivo final\n",
        "final_output_path = '/content/restaurantes_final.csv'\n",
        "merged_df.to_csv(final_output_path, index=False)\n",
        "\n",
        "print(f\"\\nArchivo final procesado y guardado en: {final_output_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrSMlhT2NNDs",
        "outputId": "f47325a5-a1f5-405d-f334-fee78869f35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Claves únicas en combined_df:\n",
            "   id_ciudad           ciudad codigo_postal_ciudad\n",
            "0       20si           apopka                32811\n",
            "2       w2w7          brandon                33605\n",
            "4       at0h  west palm beach                33436\n",
            "5       20si           apopka                32801\n",
            "6       20si           apopka                32825\n",
            "7       w2w7          brandon                33607\n",
            "8       w2w7          brandon                33602\n",
            "9       w2w7          brandon                33606\n",
            "10      w2w7          brandon                33617\n",
            "12      w2w7          brandon                33620\n",
            "\n",
            "Claves únicas en ciudades_dim:\n",
            "  id_ciudad             ciudad codigo_postal_ciudad\n",
            "0      rkx1           aberdeen                33472\n",
            "1      ikse            alachua                32601\n",
            "2      ikse            alachua                32605\n",
            "3      ikse            alachua                32608\n",
            "4      jccr  alexander springs                32702\n",
            "5      1ck3             alford                32420\n",
            "6      c6xs          allandale                32127\n",
            "7      8kez          allentown                32570\n",
            "8      aklw    alligator point                32346\n",
            "9      xzbo  altamonte springs                32701\n",
            "\n",
            "Datos faltantes en columnas relacionadas con el condado:\n",
            "id_condado               8125\n",
            "condado                  8125\n",
            "codigo_postal_condado    8125\n",
            "latitud_condado          8125\n",
            "longitud_condado         8125\n",
            "dtype: int64\n",
            "\n",
            "Filas sin coincidencia (primeras 10):\n",
            "  id_ciudad           ciudad codigo_postal_ciudad\n",
            "0      20si           apopka                32811\n",
            "1      20si           apopka                32811\n",
            "2      w2w7          brandon                33605\n",
            "3      w2w7          brandon                33605\n",
            "4      at0h  west palm beach                33436\n",
            "5      20si           apopka                32801\n",
            "6      20si           apopka                32825\n",
            "7      w2w7          brandon                33607\n",
            "8      w2w7          brandon                33602\n",
            "9      w2w7          brandon                33606\n",
            "\n",
            "Filas sin coincidencias guardadas en: /content/unmatched_rows.csv\n",
            "\n",
            "Archivo final procesado y guardado en: /content/restaurantes_final.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Completamos los datos de ciudad"
      ],
      "metadata": {
        "id": "dyzQ1XILwIon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Cargamos los archivos\n",
        "restaurantes_file = '/content/restaurantes_final.csv'\n",
        "ciudades_dim_file = '/content/sample_data/ciudades_dim.csv'\n",
        "\n",
        "restaurantes_df = pd.read_csv(restaurantes_file)\n",
        "ciudades_dim_df = pd.read_csv(ciudades_dim_file)\n",
        "\n",
        "# Normalizamos las  claves en ambos DataFrames\n",
        "restaurantes_df['ciudad'] = restaurantes_df['ciudad'].astype(str).str.strip().str.lower()\n",
        "ciudades_dim_df['ciudad'] = ciudades_dim_df['ciudad'].astype(str).str.strip().str.lower()\n",
        "\n",
        "# Realizamos el merge\n",
        "merged_df = restaurantes_df.merge(\n",
        "    ciudades_dim_df[['id_condado', 'condado', 'codigo_postal_condado', 'latitud_condado', 'longitud_condado', 'ciudad']],\n",
        "    on='ciudad',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Eliminamos columnas duplicadas\n",
        "merged_df = merged_df.drop(columns=['id_condado_x', 'condado_x', 'codigo_postal_condado_x', 'latitud_condado_x', 'longitud_condado_x'], errors='ignore')\n",
        "\n",
        "# Renombramos columnas terminadas en '_y'\n",
        "merged_df.rename(columns={\n",
        "    'id_condado_y': 'id_condado',\n",
        "    'condado_y': 'condado',\n",
        "    'codigo_postal_condado_y': 'codigo_postal_condado',\n",
        "    'latitud_condado_y': 'latitud_condado',\n",
        "    'longitud_condado_y': 'longitud_condado'\n",
        "}, inplace=True)\n",
        "\n",
        "# Guardamos el archivo actualizado\n",
        "output_path = '/content/restaurantes_final_actualizado.csv'\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Archivo final actualizado guardado en: {output_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPizAsUFYGdm",
        "outputId": "7dc95333-21d3-44a6-d85e-53f3e695307f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo final actualizado guardado en: /content/restaurantes_final_actualizado.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reordenamos las columnas"
      ],
      "metadata": {
        "id": "itc7A1KjwiJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos la ruta del archivo\n",
        "input_path = '/content/restaurantes_final_actualizado.csv'\n",
        "merged_df = pd.read_csv(input_path)\n",
        "\n",
        "# Definir el orden de las columnas deseado\n",
        "ordered_columns = [\n",
        "    'id_servicios_restaurantes', 'servicios_restaurantes', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado', 'id_ciudad', 'ciudad', 'codigo_postal_ciudad',\n",
        "    'latitud_ciudad', 'longitud_ciudad', 'estado', 'atributos', 'categorias', 'puntuacion_usuarios',\n",
        "    'numero_de_reviews', 'analisis_sentimientos', 'url_del_negocio', 'enlaces_google_maps', 'anio'\n",
        "]\n",
        "\n",
        "\n",
        "for col in ordered_columns:\n",
        "    if col not in merged_df.columns:\n",
        "        merged_df[col] = None\n",
        "\n",
        "\n",
        "merged_df = merged_df[ordered_columns]\n",
        "\n",
        "# Guardamos el archivo ordenado\n",
        "output_path = '/content/restaurantes_final_ordenado.csv'\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Archivo con columnas ordenadas guardado en: {output_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72H_bTeHarjQ",
        "outputId": "0eac32e2-75f8-4cb1-b903-954e64a0bb5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo con columnas ordenadas guardado en: /content/restaurantes_final_ordenado.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Canbiamos los nombres de clolumnas"
      ],
      "metadata": {
        "id": "UneXJ9kSw8p5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los archivos\n",
        "file1 = '/content/drive/MyDrive/categorias10/restaurantes_actualizado.csv'\n",
        "file2 = '/content/drive/MyDrive/categorias3.3/restaurantes_ordenado.csv'\n",
        "\n",
        "df1 = pd.read_csv(file1)\n",
        "df2 = pd.read_csv(file2)\n",
        "\n",
        "# Renombramos las columnas en ambos DataFrames\n",
        "rename_mapping = {\n",
        "    'id_centros_educacion': 'id_servicios_restaurantes',\n",
        "    'centros_restaurantes': 'servicios_restaurantes'\n",
        "}\n",
        "\n",
        "df1.rename(columns=rename_mapping, inplace=True)\n",
        "df2.rename(columns=rename_mapping, inplace=True)\n",
        "\n",
        "# Guardamos los archivos actualizados\n",
        "file1_output = '/content/drive/MyDrive/categorias10/restaurantes_actualizado_renombrado.csv'\n",
        "file2_output = '/content/drive/MyDrive/categorias3.3/restaurantes_ordenado_renombrado.csv'\n",
        "\n",
        "df1.to_csv(file1_output, index=False)\n",
        "df2.to_csv(file2_output, index=False)\n",
        "\n",
        "file1_output, file2_output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdHATkbLeLMS",
        "outputId": "f69c37ef-2131-41f2-dd7b-c8b4f26cf399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/categorias10/restaurantes_actualizado_renombrado.csv',\n",
              " '/content/drive/MyDrive/categorias3.3/restaurantes_ordenado_renombrado.csv')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unificamos los nombres en las columnas"
      ],
      "metadata": {
        "id": "ps9ujAxexmm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos la ruta de entrada y salida\n",
        "input_file = '/content/drive/MyDrive/categorias10/restaurantes_actualizado_renombrado.csv'\n",
        "output_file = '/content/drive/MyDrive/categorias10/restaurantes_actualizado_renombrado_corrigido.csv'\n",
        "\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Renombramos las columnas\n",
        "column_renames = {\n",
        "    'atributo': 'atributos',\n",
        "    'categoria': 'categorias',\n",
        "    '.url': 'url_del_negocio',\n",
        "    'ranquing_por_usuario': 'puntuacion_usuarios',\n",
        "    'id_centros_restaurantes':'id_servicios_restaurantes'\n",
        "}\n",
        "\n",
        "df.rename(columns=column_renames, inplace=True)\n",
        "\n",
        "# Guardamos el archivo actualizado\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Archivo actualizado guardado en: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz4uaHD5z1nl",
        "outputId": "51d4a49c-bfd2-46da-c88c-48c2a6f396cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo actualizado guardado en: /content/drive/MyDrive/categorias10/restaurantes_actualizado_renombrado_corrigido.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unificamos los archivos obtenidos  de Google Yelp y Overpass"
      ],
      "metadata": {
        "id": "e37ADH49x6KP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los archivos necesarios para el merge\n",
        "\n",
        "file1 = '/content/restaurantes_final_actualizado.csv'\n",
        "file2 = '/content/drive/MyDrive/categorias10/restaurantes_actualizado_renombrado_corrigido.csv'\n",
        "file3 = '/content/drive/MyDrive/categorias3.3/restaurantes_ordenado_renombrado.csv'\n",
        "\n",
        "df1 = pd.read_csv(file1)\n",
        "df2 = pd.read_csv(file2)\n",
        "df3 = pd.read_csv(file3)\n",
        "\n",
        "# Realizamos el merge de los tres archivos\n",
        "merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "\n",
        "required_columns = [\n",
        "    'id_servicios_restaurantes', 'servicios_restaurantes', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado', 'id_ciudad', 'ciudad', 'codigo_postal_ciudad',\n",
        "    'latitud_ciudad', 'longitud_ciudad', 'estado', 'atributos', 'categorias', 'puntuacion_usuarios',\n",
        "    'numero_de_reviews', 'analisis_sentimientos', 'url_del_negocio', 'enlaces_google_maps', 'anio'\n",
        "]\n",
        "\n",
        "for col in required_columns:\n",
        "    if col not in merged_df.columns:\n",
        "        merged_df[col] = None\n",
        "\n",
        "# Ordenamos las columnas\n",
        "merged_df = merged_df[required_columns]\n",
        "\n",
        "# Eliminamos duplicados\n",
        "merged_df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Guardamos el resultado final\n",
        "output_path = '/content/sample_data/servicio_de_restaurant_ordenado.csv'\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Archivo combinado, sin duplicados y con columnas ordenadas guardado en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdLghuMwzGUx",
        "outputId": "8cdae390-cc61-4841-ac2c-8d473cd3b724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo combinado, sin duplicados y con columnas ordenadas guardado en: /content/sample_data/servicio_de_restaurant_ordenado.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminamos caracteres inesesarios"
      ],
      "metadata": {
        "id": "gC3VjE0uyd2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos el archivo a prosesar\n",
        "input_file = '/content/sample_data/servicio_de_restaurant_ordenado.csv'\n",
        "output_file = '/content/sample_data/servicio_de_restaurant_ordenado2.csv'\n",
        "\n",
        "df = pd.read_csv(input_file, dtype={'id_centros_entretenimiento': 'string'}, low_memory=False)\n",
        "\n",
        "# Normalizamos los nombres de las columnas\n",
        "df.columns = [\n",
        "    col_name.strip()\n",
        "    .replace(\" \", \"_\")\n",
        "    .replace(\",\", \"\")\n",
        "    .replace(\"(\", \"\")\n",
        "    .replace(\")\", \"\")\n",
        "    .replace(\"$\", \"\")\n",
        "    .replace(\";\", \"\")\n",
        "    .replace(\"=\", \"\")\n",
        "    .replace(\".\", \"_\")\n",
        "    .replace(\"\\n\", \"\")\n",
        "    .replace(\"\\t\", \"\")\n",
        "    for col_name in df.columns\n",
        "]\n",
        "\n",
        "# Asignar el formatos a las columnas\n",
        "column_types = {\n",
        "    'id_centros_entretenimiento': 'string',\n",
        "    'centros_entretenimiento': 'string',\n",
        "    'direccion': 'string',\n",
        "    'id_condado': 'string',\n",
        "    'condado': 'string',\n",
        "    'codigo_postal_condado': 'string',\n",
        "    'latitud_condado': 'float',\n",
        "    'longitud_condado': 'float',\n",
        "    'id_ciudad': 'string',\n",
        "    'ciudad': 'string',\n",
        "    'codigo_postal_ciudad': 'string',\n",
        "    'latitud_ciudad': 'float',\n",
        "    'longitud_ciudad': 'float',\n",
        "    'estado': 'string',\n",
        "    'categorias': 'string',\n",
        "    'puntuacion_usuarios': 'float',\n",
        "    'analisis_sentimientos': 'string',\n",
        "    'url_del_negocio': 'string',\n",
        "    'enlaces_google_maps': 'string',\n",
        "    'anio': 'int'\n",
        "}\n",
        "\n",
        "for column, dtype in column_types.items():\n",
        "    if column in df.columns:\n",
        "        df[column] = df[column].astype(dtype)\n",
        "\n",
        "# Eliminamos caracteres no deseados en todas las columnas de tipo string\n",
        "columns_to_clean = df.select_dtypes(include=['string']).columns\n",
        "df[columns_to_clean] = df[columns_to_clean].replace(\n",
        "    to_replace=r\"[\\[\\]\\{\\}'\\\"]\", value=\"\", regex=True\n",
        ")\n",
        "\n",
        "# Guardamos el archivo procesado\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Archivo procesado y guardado en: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkinW4E9gIG7",
        "outputId": "288591ca-33ff-49b4-dc31-9798d0172fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo procesado y guardado en: /content/sample_data/servicio_de_restaurant_ordenado2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ISn9IZ92O2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unificamos los nombres delos archivos"
      ],
      "metadata": {
        "id": "SW75ucFd2ccv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los archivos de entrada y salida\n",
        "input_file = '/content/drive/MyDrive/categorias10/servicios_hosteleria.csv'\n",
        "output_file = '/content/drive/MyDrive/categorias10/servicios_hosteleria_coregido.csv'\n",
        "\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Renombramos las columnas\n",
        "column_renames = {\n",
        "    'atributo': 'atributos',\n",
        "    'categoria': 'categorias',\n",
        "    '.url': 'url_del_negocio',\n",
        "    'ranquing_por_usuario': 'puntuacion_usuarios'\n",
        "\n",
        "}\n",
        "\n",
        "df.rename(columns=column_renames, inplace=True)\n",
        "\n",
        "# Guardamos el archivo actualizado\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Archivo actualizado guardado en: {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeqcd39m2YKE",
        "outputId": "d673929c-a313-4843-bc41-bc97ee92877a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo actualizado guardado en: /content/drive/MyDrive/categorias10/servicios_hosteleria_coregido.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unificamos los archivos obtenidos  de Google  y Yelp"
      ],
      "metadata": {
        "id": "JKs6NDbtkav1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos los archivos de entrada y salida\n",
        "file1 = '/content/drive/MyDrive/categorias10/servicios_hosteleria_coregido.csv'\n",
        "file2 = '/content/drive/MyDrive/categorias3.3/hosteleria_ordenado.csv'\n",
        "\n",
        "df1 = pd.read_csv(file1)\n",
        "df2 = pd.read_csv(file2)\n",
        "\n",
        "# Realizamos el merge\n",
        "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "required_columns = [\n",
        "    'id_centros_hosteleria', 'centros_hosteleria', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado', 'id_ciudad', 'ciudad',\n",
        "    'codigo_postal_ciudad', 'latitud_ciudad', 'longitud_ciudad', 'estado', 'atributos',\n",
        "    'categorias', 'puntuacion_usuarios', 'numero_de_reviews', 'analisis_sentimientos',\n",
        "    'url_del_negocio', 'enlaces_google_maps', 'anio'\n",
        "]\n",
        "\n",
        "for col in required_columns:\n",
        "    if col not in merged_df.columns:\n",
        "        merged_df[col] = None\n",
        "\n",
        "# Ordenamos las columnas\n",
        "merged_df = merged_df[required_columns]\n",
        "\n",
        "# Eliminamos duplicados\n",
        "merged_df['non_null_count'] = merged_df.notna().sum(axis=1)\n",
        "merged_df = merged_df.sort_values(by='non_null_count', ascending=False)\n",
        "merged_df = merged_df.drop_duplicates(subset=['id_centros_hosteleria', 'anio'], keep='first')\n",
        "\n",
        "# Ordenamos los datos por la columna 'anio' de menor a mayor\n",
        "merged_df = merged_df.sort_values(by='anio', ascending=True).drop(columns=['non_null_count'], errors='ignore')\n",
        "\n",
        "# Guardamos los resultados\n",
        "output_path = '/content/sample_data/servicio_hospedaje.csv'\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Archivo combinado, sin duplicados y con columnas preservadas guardado en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dbuXtUo0VHO",
        "outputId": "b486ddbe-098e-42e4-caf5-d6a5d7e28b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo combinado, sin duplicados y con columnas preservadas guardado en: /content/sample_data/servicio_hospedaje.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminamos caracteres inesesarios y damos un formato unificado a las columnas"
      ],
      "metadata": {
        "id": "uCrp22O87NDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los archivos de entrada y salida\n",
        "input_file = '/content/sample_data/servicio_hospedaje.csv'\n",
        "output_file = '/content/sample_data/servicio_hospedaje2.csv'\n",
        "\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Normalizamos nombres de columnas\n",
        "df.columns = [\n",
        "    col_name.strip()\n",
        "    .replace(\" \", \"_\")\n",
        "    .replace(\",\", \"\")\n",
        "    .replace(\"(\", \"\")\n",
        "    .replace(\")\", \"\")\n",
        "    .replace(\"$\", \"\")\n",
        "    .replace(\";\", \"\")\n",
        "    .replace(\"=\", \"\")\n",
        "    .replace(\".\", \"_\")\n",
        "    .replace(\"\\n\", \"\")\n",
        "    .replace(\"\\t\", \"\")\n",
        "    for col_name in df.columns\n",
        "]\n",
        "\n",
        "# Asignamos el tipo de datos a las columnas\n",
        "column_types = {\n",
        "    'id_centros_hosteleria': 'string',\n",
        "    'centros_hosteleria': 'string',\n",
        "    'direccion': 'string',\n",
        "    'id_condado': 'string',\n",
        "    'condado': 'string',\n",
        "    'codigo_postal_condado': 'string',\n",
        "    'latitud_condado': 'float',\n",
        "    'longitud_condado': 'float',\n",
        "    'id_ciudad': 'string',\n",
        "    'ciudad': 'string',\n",
        "    'codigo_postal_ciudad': 'string',\n",
        "    'latitud_ciudad': 'float',\n",
        "    'longitud_ciudad': 'float',\n",
        "    'estado': 'string',\n",
        "    'categorias': 'string',\n",
        "    'puntuacion_usuarios': 'float',\n",
        "    'analisis_sentimientos': 'string',\n",
        "    'url_del_negocio': 'string',\n",
        "    'enlaces_google_maps': 'string',\n",
        "    'anio': 'int'\n",
        "}\n",
        "\n",
        "for column, dtype in column_types.items():\n",
        "    if column in df.columns:\n",
        "        df[column] = df[column].astype(dtype)\n",
        "\n",
        "# Eliminamos caracteres no deseados en todas las columnas de tipo string\n",
        "columns_to_clean = df.select_dtypes(include=['string']).columns\n",
        "df[columns_to_clean] = df[columns_to_clean].replace(\n",
        "    to_replace=r\"[\\[\\]\\{\\}'\\\"]\", value=\"\", regex=True\n",
        ")\n",
        "\n",
        "\n",
        "# Guardamos el archivo prosesado\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Archivo procesado y guardado en: {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGGG3MCHhdkq",
        "outputId": "3c9837f0-483e-4583-e9ab-ffcd1e0188ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo procesado y guardado en: /content/sample_data/servicio_hospedaje2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Renombramos columnas para poder realisar el merge"
      ],
      "metadata": {
        "id": "av55lreo7ZT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los archivos de entrada y salida\n",
        "input_file = '/content/drive/MyDrive/categorias10/tiendas_negocio_actualizado.csv'\n",
        "output_file = '/content/drive/MyDrive/categorias10/tiendas_negocio_actualizado_coregido.csv'\n",
        "\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Renombramos las columnas\n",
        "column_renames = {\n",
        "    'atributo': 'atributos',\n",
        "    'categoria': 'categorias',\n",
        "    '.url': 'url_del_negocio',\n",
        "    'ranquing_por_usuario': 'puntuacion_usuarios'\n",
        "\n",
        "}\n",
        "\n",
        "df.rename(columns=column_renames, inplace=True)\n",
        "\n",
        "# Guardamos el archivo actualizado\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Archivo actualizado guardado en: {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i7_PZpo38ms",
        "outputId": "48459927-6537-4e16-de78-b973652be702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo actualizado guardado en: /content/drive/MyDrive/categorias10/tiendas_negocio_actualizado_coregido.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unificamos los archivos obtenidos  de Google y Yelp"
      ],
      "metadata": {
        "id": "zE9mVdpr8whr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos los archivos nesesarios para el merge\n",
        "file1 = '/content/drive/MyDrive/categorias10/tiendas_negocio_actualizado_coregido.csv'\n",
        "file2 = '/content/drive/MyDrive/categorias3.3/servicio_tiendas_negocio_ordenado.csv'\n",
        "\n",
        "df1 = pd.read_csv(file1)\n",
        "df2 = pd.read_csv(file2)\n",
        "\n",
        "#Realizamos el merge de los archivos, preservando todas las columnas\n",
        "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "required_columns = [\n",
        "    'id_centros_tiendas_negocio', 'centros_tiendas_negocio', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado', 'id_ciudad', 'ciudad',\n",
        "    'codigo_postal_ciudad', 'latitud_ciudad', 'longitud_ciudad', 'estado', 'atributos',\n",
        "    'categorias', 'puntuacion_usuarios', 'numero_de_reviews', 'analisis_sentimientos',\n",
        "    'url', 'enlaces_google_maps', 'anio'\n",
        "]\n",
        "\n",
        "for col in required_columns:\n",
        "    if col not in merged_df.columns:\n",
        "        merged_df[col] = pd.NA\n",
        "\n",
        "# Reordenamos las columnas\n",
        "merged_df = merged_df[required_columns]\n",
        "\n",
        "# Guardamos el resultado\n",
        "output_path = '/content/servicio_tiendas_negocios_combinedo4.csv'\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Archivo combinado guardado en: {output_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZcZo26C1XMi",
        "outputId": "020e72e1-c27e-4c89-e29d-fb9ada32c60a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo combinado guardado en: /content/servicio_tiendas_negocios_combinedo4.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminamos caracteres innesesarios"
      ],
      "metadata": {
        "id": "0SkRBjZQ9Ndk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los archivos de entrada y salida\n",
        "input_file = '/content/servicio_tiendas_negocios_combinedo4.csv'\n",
        "output_file = '/content/servicio_tiendas_negocios_combinedo5.csv'\n",
        "\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Normalizamos las columnas\n",
        "df.columns = [\n",
        "    col_name.strip()\n",
        "    .replace(\" \", \"_\")\n",
        "    .replace(\",\", \"\")\n",
        "    .replace(\"(\", \"\")\n",
        "    .replace(\")\", \"\")\n",
        "    .replace(\"$\", \"\")\n",
        "    .replace(\";\", \"\")\n",
        "    .replace(\"=\", \"\")\n",
        "    .replace(\".\", \"_\")\n",
        "    .replace(\"\\n\", \"\")\n",
        "    .replace(\"\\t\", \"\")\n",
        "    for col_name in df.columns\n",
        "]\n",
        "\n",
        "# Asignmos formato a las columnas\n",
        "column_types = {\n",
        "    'id_centros_tiendas_negocio': 'string',\n",
        "    'centros_tiendas_negocio': 'string',\n",
        "    'direccion': 'string',\n",
        "    'id_condado': 'string',\n",
        "    'condado': 'string',\n",
        "    'codigo_postal_condado': 'string',\n",
        "    'latitud_condado': 'float',\n",
        "    'longitud_condado': 'float',\n",
        "    'id_ciudad': 'string',\n",
        "    'ciudad': 'string',\n",
        "    'codigo_postal_ciudad': 'string',\n",
        "    'latitud_ciudad': 'float',\n",
        "    'longitud_ciudad': 'float',\n",
        "    'estado': 'string',\n",
        "    'categorias': 'string',\n",
        "    'puntuacion_usuarios': 'float',\n",
        "    'analisis_sentimientos': 'string',\n",
        "    'url_del_negocio': 'string',\n",
        "    'enlaces_google_maps': 'string',\n",
        "    'anio': 'Int64'  }\n",
        "\n",
        "for column, dtype in column_types.items():\n",
        "    if column in df.columns:\n",
        "        try:\n",
        "            df[column] = df[column].astype(dtype)\n",
        "        except ValueError as e:\n",
        "            print(f\"Error al convertir la columna {column}: {e}\")\n",
        "\n",
        "# Limpiamos caracteres no deseados en columnas\n",
        "columns_to_clean = df.select_dtypes(include=['string']).columns\n",
        "df[columns_to_clean] = df[columns_to_clean].replace(\n",
        "    to_replace=r\"[\\[\\]\\{\\}'\\\"]\", value=\"\", regex=True\n",
        ")\n",
        "\n",
        "# Guardamos el archivo procesado\n",
        "df.to_csv(output_file, index=False)\n",
        "print(f\"Archivo procesado y guardado en: {output_file}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSQbbmHdmRO4",
        "outputId": "3cfa9dd0-9e99-475c-b6ca-5190ff2d88f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo procesado y guardado en: /content/servicio_tiendas_negocios_combinedo5.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unificamos nombres en los archivos"
      ],
      "metadata": {
        "id": "H0jQ_sKT-TkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los archivos de entrada y salida\n",
        "input_file = '/content/drive/MyDrive/categorias10/transporte_actualizado.csv'\n",
        "output_file = '/content/drive/MyDrive/categorias10/transporte_actualizado_coregido.csv'\n",
        "\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Renombramos las columnas\n",
        "column_renames = {\n",
        "    'atributo': 'atributos',\n",
        "    'categoria': 'categorias',\n",
        "    '.url': 'url_del_negocio',\n",
        "    'ranquing_por_usuario': 'puntuacion_usuarios'\n",
        "\n",
        "}\n",
        "\n",
        "df.rename(columns=column_renames, inplace=True)\n",
        "\n",
        "# Guardamos el archivo actualizado\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Archivo actualizado guardado en: {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAzb31HvuIoW",
        "outputId": "979de6b5-e2bb-46c8-c038-6b493e0cd57d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo actualizado guardado en: /content/drive/MyDrive/categorias10/transporte_actualizado_coregido.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cargamos los archivos a comcatenar\n",
        "file1 = '/content/drive/MyDrive/categorias10/transporte_actualizado.csv'\n",
        "file2 = '/content/drive/MyDrive/categorias3.3/servicio_transporte_ordenado.csv'\n",
        "\n",
        "df1 = pd.read_csv(file1)\n",
        "df2 = pd.read_csv(file2)\n",
        "\n",
        "df1.rename(columns={'id_transporte': 'id_trasporte', 'transporte': 'trasporte'}, inplace=True)\n",
        "df2.rename(columns={'id_transporte': 'id_trasporte', 'transporte': 'trasporte'}, inplace=True)\n",
        "\n",
        "# Concatenamos los archivos\n",
        "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "required_columns = [\n",
        "    'id_trasporte', 'trasporte', 'direccion', 'id_condado', 'condado',\n",
        "    'codigo_postal_condado', 'latitud_condado', 'longitud_condado', 'id_ciudad', 'ciudad',\n",
        "    'codigo_postal_ciudad', 'latitud_ciudad', 'longitud_ciudad', 'estado', 'atributos',\n",
        "    'categorias', 'puntuacion_usuarios', 'numero_de_reviews', 'analisis_sentimientos',\n",
        "    'url', 'enlaces_google_maps', 'anio'\n",
        "]\n",
        "\n",
        "for col in required_columns:\n",
        "    if col not in merged_df.columns:\n",
        "        merged_df[col] = pd.NA\n",
        "\n",
        "\n",
        "merged_df = merged_df[required_columns]\n",
        "\n",
        "output_path = '/content/sample_data/servicio_transporte_ordenado2.csv'\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Archivo combinado guardado en: {output_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqeXtZkx2vGu",
        "outputId": "67e81c62-7dc2-4dbc-bddb-24f83166e332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo combinado guardado en: /content/sample_data/servicio_transporte_ordenado2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminamos caracteres innesesarios"
      ],
      "metadata": {
        "id": "EQCcxSts-yGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos las rutas delos archivos\n",
        "input_file = '/content/sample_data/servicio_transporte_ordenado2.csv'\n",
        "output_file = '/content/sample_data/servicio_transporte_ordenado3.csv'\n",
        "\n",
        "if not os.path.exists(input_file):\n",
        "    print(f\"El archivo no se encontró: {input_file}\")\n",
        "    exit()\n",
        "\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Normalizamos los nombres de columnas\n",
        "df.columns = [\n",
        "    col_name.strip()\n",
        "    .replace(\" \", \"_\")\n",
        "    .replace(\",\", \"\")\n",
        "    .replace(\"(\", \"\")\n",
        "    .replace(\")\", \"\")\n",
        "    .replace(\"$\", \"\")\n",
        "    .replace(\";\", \"\")\n",
        "    .replace(\"=\", \"\")\n",
        "    .replace(\".\", \"_\")\n",
        "    .replace(\"\\n\", \"\")\n",
        "    .replace(\"\\t\", \"\")\n",
        "    for col_name in df.columns\n",
        "]\n",
        "\n",
        "# Asignamos el formato correspondiente a cada columna\n",
        "column_types = {\n",
        "    'id_centros_tiendas_negocio': 'string',\n",
        "    'centros_tiendas_negocio': 'string',\n",
        "    'direccion': 'string',\n",
        "    'id_condado': 'string',\n",
        "    'condado': 'string',\n",
        "    'codigo_postal_condado': 'string',\n",
        "    'latitud_condado': 'float',\n",
        "    'longitud_condado': 'float',\n",
        "    'id_ciudad': 'string',\n",
        "    'ciudad': 'string',\n",
        "    'codigo_postal_ciudad': 'string',\n",
        "    'latitud_ciudad': 'float',\n",
        "    'longitud_ciudad': 'float',\n",
        "    'estado': 'string',\n",
        "    'categorias': 'string',\n",
        "    'puntuacion_usuarios': 'float',\n",
        "    'analisis_sentimientos': 'string',\n",
        "    'url_del_negocio': 'string',\n",
        "    'enlaces_google_maps': 'string',\n",
        "    'anio': 'int'\n",
        "}\n",
        "\n",
        "for column, dtype in column_types.items():\n",
        "    if column in df.columns:\n",
        "        df[column] = df[column].astype(dtype)\n",
        "\n",
        "# Limpiamos los caracteres no deseados en columnas\n",
        "columns_to_clean = df.select_dtypes(include=['string']).columns\n",
        "df[columns_to_clean] = df[columns_to_clean].replace(\n",
        "    to_replace=r\"[\\[\\]\\{\\}'\\\"]\", value=\"\", regex=True\n",
        ")\n",
        "\n",
        "# Guardamos el archivo procesado\n",
        "df.to_csv(output_file, index=False)\n",
        "print(f\"Archivo procesado y guardado en: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA_WqEynuiOZ",
        "outputId": "a7b0a87c-a652-4255-a6c2-88601855e4d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo procesado y guardado en: /content/sample_data/servicio_transporte_ordenado3.csv\n"
          ]
        }
      ]
    }
  ]
}