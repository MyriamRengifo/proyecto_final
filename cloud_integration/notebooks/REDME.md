# üìÇ Carga y Transformaci√≥n de Datos

## üìÑ Descripci√≥n
El notebook **carga y transformaci√≥n de datos.ipynb** est√° dise√±ado para:
- Cargar archivos desde el **Databricks File System (DBFS)**.
- Transformar los datos en formato **Delta**.
- Almacenarlos en el **Unity Catalog** de Databricks, optimizando los datos para su an√°lisis y consultas.

---

## üõ†Ô∏è Funcionalidades Principales

1. **Listar Archivos Disponibles**  
   - Verifica y lista los archivos cargados en la ruta especificada del **DBFS**.

2. **Carga de Archivos**  
   - Lee los datos desde archivos CSV utilizando **Spark DataFrames** con detecci√≥n autom√°tica de esquemas.

3. **Transformaci√≥n a Delta Tables**  
   - Convierte los archivos CSV en **Tablas Delta**, almacen√°ndolos en el **Unity Catalog**.

4. **Validaci√≥n de Tablas**  
   - Verifica la creaci√≥n de las tablas Delta mediante comandos SQL.

5. **Inspecci√≥n de Datos Crudos**  
   - Inspecciona la estructura de los datos almacenados en el sistema de archivos de Databricks (**DBFS**).

---

## üìã Proceso de Ejecuci√≥n

### 1. **Listar Archivos en DBFS**
   - El notebook utiliza `dbutils.fs.ls()` para verificar los archivos disponibles en la ruta:  
     `dbfs:/Volumes/aprendisaje/default/servicios2/`.

### 2. **Carga y Procesamiento de Archivos**
   - Los datos procesados incluyen informaci√≥n sobre servicios educativos, entretenimiento, transporte y restaurantes.

### 3. **Creaci√≥n de Tablas Delta**
   - Los archivos son cargados como **Spark DataFrames**, procesados y almacenados como tablas Delta dentro del esquema:  
     `aprendisaje.default`.

### 4. **Validaci√≥n de Tablas**
   - Comando SQL para listar y validar las tablas creadas:  
     ```sql
     SHOW TABLES IN aprendisaje.default;
     ```

### 5. **Inspecci√≥n de Datos Crudos**
   - Comando para inspeccionar los archivos en DBFS:  
     ```python
     dbutils.fs.ls("dbfs:/mnt/ingest_data/raw/")
     ```

---

## üìÅ Archivos Procesados

Los siguientes archivos son procesados y convertidos a tablas Delta:

- `centros_educacion_dim.csv`  
- `centros_entretenimiento_dim.csv`  
- `centros_hosteleria_dim.csv`  
- `ciudades_dim.csv`  
- `servicio_restaurantes.csv`  
- `servicio_tiendas_negocio_dim.csv`  
- `servicio_tiendas_negocios.csv`  
- `servicio_transporte.csv`  
- `servicio_transporte_dim.csv`  
- `servicios_educacion.csv`  
- `servicios_entretenimiento.csv`  
- `servicios_hospedaje.csv`  
- `servicios_restaurantes_dim.csv`  

---

## üåü Ventajas del Proceso

1. **Optimizaci√≥n del Rendimiento:**  
   - Mejora la velocidad y eficiencia de las consultas utilizando tablas Delta.

2. **Estandarizaci√≥n de Datos:**  
   - Garantiza un formato estructurado y consistente para todos los datos.

3. **Automatizaci√≥n:**  
   - Simplifica y acelera el proceso de carga y transformaci√≥n.

4. **Flexibilidad:**  
   - Permite a√±adir nuevos archivos f√°cilmente al flujo.

---

## üö® Notas Importantes

1. **Configuraci√≥n Inicial:**  
   - Aseg√∫rate de que los archivos est√©n en la ruta especificada antes de ejecutar el notebook.

2. **Validaci√≥n de Rutas:**  
   - Verifica que los nombres y rutas de los archivos sean correctos.

3. **Consistencia de Esquemas:**  
   - Aseg√∫rate de que los esquemas de los datos sean consistentes para evitar errores.

---

Con este notebook, simplificamos y estandarizamos el proceso de carga y transformaci√≥n de datos en Databricks, asegurando que los datos est√©n listos para an√°lisis avanzados y modelado. üöÄ
üòä
